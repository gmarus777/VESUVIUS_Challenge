{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b28f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge/jupyter notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-18:] == 'VESUVIUS_Challenge':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8ebda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-30 12:47:44,599 - Created a temporary directory at /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmpcuh8rh90\n",
      "2023-04-30 12:47:44,599 - Writing /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmpcuh8rh90/_remote_module_non_scriptable.py\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from Data_Modules.MONAI_Dict_Dataset_Module import MONAI_CSV_Scrolls_Dataset\n",
    "import matplotlib.patches as patches\n",
    "from lit_models.UNET_monai_lit import UNET_lit\n",
    "from monai.visualize import matshow3d\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='TypedStorage is deprecated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023ec0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_DIR = PATH / \"kaggle\"\n",
    "\n",
    "INPUT_DIR = KAGGLE_DIR / \"input\"\n",
    "\n",
    "COMPETITION_DATA_DIR = INPUT_DIR / \"vesuvius-challenge-ink-detection\"\n",
    "\n",
    "TRAIN_DATA_CSV_PATH = COMPETITION_DATA_DIR / \"data_train_0.5.csv\"\n",
    "TEST_DATA_CSV_PATH = COMPETITION_DATA_DIR / \"data_test_1.0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e54078",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MONAI_CSV_Scrolls_Dataset(\n",
    "                                z_dim=4,\n",
    "                                batch_size=1,\n",
    "                                data_csv_path=TRAIN_DATA_CSV_PATH,\n",
    "                                num_workers=8,\n",
    "                                num_samples=16,\n",
    "                                patch_size=(512,512),\n",
    "                                val_fragment_id=1,\n",
    "                                on_gpu=False,\n",
    "\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8db412",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = UNET_lit(\n",
    "        use_wandb = False,\n",
    "        z_dim = 4,\n",
    "        patch_size = (512,512),\n",
    "        sw_batch_size=8 ,\n",
    "        eta_min = 1e-8,\n",
    "        t_max = 250,\n",
    "        max_epochs = 1000,\n",
    "        weight_decay =  0.001,\n",
    "        learning_rate = 0.0001,\n",
    "        gamma = 0.85,)\n",
    "\n",
    "#lit_model = lit_model.load_from_checkpoint('logs/FocalDICE_512_monai_unet_16_cont/lightning_logs/version_0/checkpoints/epoch=171-step=344.ckpt', \n",
    "#                                          #patch_size = (512,512),\n",
    "#                                          learning_rate = 0.00001,\n",
    "#                                           weight_decay =  .01,\n",
    "#                                           eta_min = 1e-9,\n",
    "#                                         sw_batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210eeac7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-30 12:47:45,650 - GPU available: True (mps), used: False\n",
      "2023-04-30 12:47:45,651 - TPU available: False, using: 0 TPU cores\n",
      "2023-04-30 12:47:45,651 - IPU available: False, using: 0 IPUs\n",
      "2023-04-30 12:47:45,651 - HPU available: False, using: 0 HPUs\n",
      "# train: 2\n",
      "# val: 1\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2023-04-30 12:47:45,739 - \n",
      "  | Name         | Type                  | Params\n",
      "-------------------------------------------------------\n",
      "0 | metrics      | ModuleDict            | 0     \n",
      "1 | model        | UNet                  | 122 M \n",
      "2 | loss_dice    | DiceLoss              | 0     \n",
      "3 | loss_bce     | SoftBCEWithLogitsLoss | 0     \n",
      "4 | loss_focal   | FocalLoss             | 0     \n",
      "5 | loss         | MaskedLoss            | 0     \n",
      "6 | diceloss     | DiceLoss              | 0     \n",
      "7 | masked_dice  | MaskedLoss            | 0     \n",
      "8 | focalloss    | FocalLoss             | 0     \n",
      "9 | masked_focal | MaskedLoss            | 0     \n",
      "-------------------------------------------------------\n",
      "122 M     Trainable params\n",
      "0         Non-trainable params\n",
      "122 M     Total params\n",
      "488.364   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /Users/gregory/PROJECT_ML/VESUVIUS_Challenge/logs/Full_16_768to1024_batch exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:188: UserWarning: Experiment logs directory logs/Full_16_768to1024_batch/lightning_logs/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0260a3d928aa4ba7a66d1ebe7eb8cae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=5,\n",
    "    monitor=\"FBETA\",\n",
    "    mode=\"max\",\n",
    "    dirpath=\"logs/Full_16_768to1024_batch/\",\n",
    "    filename=\"FocalDice_768{epoch:02d}{FBETA:.2f}{recall:.2f}{precision:.2f}\",\n",
    "    save_last =True,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        accelerator='cpu',\n",
    "        #benchmark=True,\n",
    "        max_epochs=100,\n",
    "        check_val_every_n_epoch= 1,\n",
    "        devices=1,\n",
    "        #fast_dev_run=fast_dev_run,\n",
    "        logger=pl.loggers.CSVLogger(save_dir='logs/Full_16_768to1024_batch/'),\n",
    "        log_every_n_steps=1,\n",
    "        default_root_dir = 'logs/Full_16_768to1024_batch/',\n",
    "        #overfit_batches=1,\n",
    "        #precision=16,\n",
    "        accumulate_grad_batches=2, \n",
    "        callbacks=[checkpoint_callback],\n",
    "        #resume_from_checkpoint ='logs/smp_unet_32_.5/lightning_logs/version_3/checkpoints/FocalDice_768epoch=123FBETA=0.30recall=0.77precision=0.26.ckpt'\n",
    "        \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer.fit(lit_model, datamodule=dataset,\n",
    "            #ckpt_path='logs/Full_16_768to1024_batch/FocalDice_768epoch=151FBETA=0.41recall=0.56precision=0.39.ckpt'\n",
    "           )\n",
    "# resume_from_checkpoint = \n",
    "#ckpt_path='logs/unet_smp-epoch=102-val_loss=0.00.ckpt'\n",
    "# ckpt_path='logs/Eff_monai_32z/lightning_logs/version_0/checkpoints/epoch=19-step=40.ckp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5970c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d11aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ee195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59ed75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44227713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
