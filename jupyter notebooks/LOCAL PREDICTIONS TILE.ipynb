{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20bcc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge/jupyter notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-18:] == 'VESUVIUS_Challenge':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54375fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:41:15,003 - Created a temporary directory at /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp42hv0l25\n",
      "2023-05-04 17:41:15,004 - Writing /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp42hv0l25/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from Data_Modules.Vesuvius_Tile_Dataset import Vesuvius_Tile_Datamodule\n",
    "import matplotlib.patches as patches\n",
    "from lit_models.UNET_TILE import UNET_TILE_lit\n",
    "from monai.visualize import matshow3d\n",
    "import einops\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import monai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image as Image\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torchmetrics import Dice,  FBetaScore\n",
    "from torchmetrics import MetricCollection\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, List\n",
    "import os\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748d238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_DIR = PATH / \"kaggle\"\n",
    "\n",
    "INPUT_DIR = KAGGLE_DIR / \"input\"\n",
    "\n",
    "COMPETITION_DATA_DIR = INPUT_DIR / \"vesuvius-challenge-ink-detection\"\n",
    "\n",
    "TRAIN_DATA_CSV_PATH = COMPETITION_DATA_DIR / \"data_train_0.5.csv\"\n",
    "TEST_DATA_CSV_PATH = COMPETITION_DATA_DIR / \"data_test_1.csv\"\n",
    "TEST_DOWNSAMPLED_DATA_CSV_PATH = COMPETITION_DATA_DIR /\"data_test_0.5.csv\"\n",
    "TEST_DOWNSAMPLED_HALf_DATA_CSV_PATH = COMPETITION_DATA_DIR /\"data_test_0.75.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92fbba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = 'logs/BCE1_SMPEffB2_Tile_12_224patch/last.ckpt'\n",
    "COMPETITION_DATA_DIR_str =  \"kaggle/input/vesuvius-challenge-ink-detection/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1526d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 224\n",
    "Z_DIM = 10\n",
    "\n",
    "class CFG:\n",
    "    \n",
    "    train_fragment_id=[2,3]\n",
    "    val_fragment_id=[1]\n",
    "    batch_size = 32\n",
    "    patch_size = PATCH_SIZE\n",
    "    z_dim = Z_DIM\n",
    "    stride = patch_size // 2\n",
    "    #comp_dataset_path = COMPETITION_DATA_DIR\n",
    "    num_workers = 0\n",
    "    on_gpu = True\n",
    "    test_fragment_ids = ['a','b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0fa122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6e25393d5d452a92506dcb9e9514f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb881b06ccf475988cd7e63a5021bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94215223f6494f7da1361ec4002121de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Vesuvius_Tile_Datamodule(cfg=CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c657bc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /Users/gregory/.cache/torch/hub/checkpoints/efficientnet-b1-f1951068.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30.1M/30.1M [00:00<00:00, 48.4MB/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UNET_TILE_lit:\n\tUnexpected key(s) in state_dict: \"loss_bce.pos_weight\". \n\tsize mismatch for model.encoder._blocks.5._project_conv.weight: copying a param with shape torch.Size([48, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 144, 1, 1]).\n\tsize mismatch for model.encoder._blocks.5._bn2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.5._bn2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.5._bn2.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.5._bn2.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.6._expand_conv.weight: copying a param with shape torch.Size([288, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for model.encoder._blocks.6._bn0.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn0.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn0.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn0.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._depthwise_conv.weight: copying a param with shape torch.Size([288, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([240, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.6._bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._se_reduce.weight: copying a param with shape torch.Size([12, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.6._se_reduce.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for model.encoder._blocks.6._se_expand.weight: copying a param with shape torch.Size([288, 12, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for model.encoder._blocks.6._se_expand.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._project_conv.weight: copying a param with shape torch.Size([48, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.6._bn2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.6._bn2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.6._bn2.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.6._bn2.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.7._expand_conv.weight: copying a param with shape torch.Size([288, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for model.encoder._blocks.7._bn0.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn0.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn0.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn0.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._depthwise_conv.weight: copying a param with shape torch.Size([288, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([240, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.7._bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._se_reduce.weight: copying a param with shape torch.Size([12, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.7._se_reduce.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for model.encoder._blocks.7._se_expand.weight: copying a param with shape torch.Size([288, 12, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for model.encoder._blocks.7._se_expand.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._project_conv.weight: copying a param with shape torch.Size([48, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.7._bn2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.7._bn2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.7._bn2.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.7._bn2.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.8._expand_conv.weight: copying a param with shape torch.Size([288, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for model.encoder._blocks.8._bn0.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn0.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn0.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn0.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._depthwise_conv.weight: copying a param with shape torch.Size([288, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.8._bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._se_reduce.weight: copying a param with shape torch.Size([12, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.8._se_reduce.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for model.encoder._blocks.8._se_expand.weight: copying a param with shape torch.Size([288, 12, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for model.encoder._blocks.8._se_expand.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._project_conv.weight: copying a param with shape torch.Size([88, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.8._bn2.weight: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.8._bn2.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.8._bn2.running_mean: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.8._bn2.running_var: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.9._expand_conv.weight: copying a param with shape torch.Size([528, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.9._bn0.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn0.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn0.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn0.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._depthwise_conv.weight: copying a param with shape torch.Size([528, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.9._bn1.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn1.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn1.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn1.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._se_reduce.weight: copying a param with shape torch.Size([22, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.9._se_reduce.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for model.encoder._blocks.9._se_expand.weight: copying a param with shape torch.Size([528, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for model.encoder._blocks.9._se_expand.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._project_conv.weight: copying a param with shape torch.Size([88, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.9._bn2.weight: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.9._bn2.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.9._bn2.running_mean: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.9._bn2.running_var: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.10._expand_conv.weight: copying a param with shape torch.Size([528, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.10._bn0.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn0.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn0.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn0.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._depthwise_conv.weight: copying a param with shape torch.Size([528, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.10._bn1.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn1.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn1.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn1.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._se_reduce.weight: copying a param with shape torch.Size([22, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.10._se_reduce.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for model.encoder._blocks.10._se_expand.weight: copying a param with shape torch.Size([528, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for model.encoder._blocks.10._se_expand.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._project_conv.weight: copying a param with shape torch.Size([88, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.10._bn2.weight: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.10._bn2.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.10._bn2.running_mean: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.10._bn2.running_var: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.11._expand_conv.weight: copying a param with shape torch.Size([528, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.11._bn0.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn0.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn0.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn0.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._depthwise_conv.weight: copying a param with shape torch.Size([528, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.11._bn1.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn1.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn1.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn1.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._se_reduce.weight: copying a param with shape torch.Size([22, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.11._se_reduce.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for model.encoder._blocks.11._se_expand.weight: copying a param with shape torch.Size([528, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for model.encoder._blocks.11._se_expand.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._project_conv.weight: copying a param with shape torch.Size([88, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.11._bn2.weight: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.11._bn2.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.11._bn2.running_mean: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.11._bn2.running_var: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.12._expand_conv.weight: copying a param with shape torch.Size([528, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.12._bn0.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn0.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn0.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn0.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._depthwise_conv.weight: copying a param with shape torch.Size([528, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([480, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.12._bn1.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn1.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn1.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn1.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._se_reduce.weight: copying a param with shape torch.Size([22, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.12._se_reduce.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for model.encoder._blocks.12._se_expand.weight: copying a param with shape torch.Size([528, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for model.encoder._blocks.12._se_expand.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._project_conv.weight: copying a param with shape torch.Size([120, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.12._bn2.weight: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.12._bn2.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.12._bn2.running_mean: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.12._bn2.running_var: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.13._expand_conv.weight: copying a param with shape torch.Size([720, 120, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for model.encoder._blocks.13._bn0.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn0.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn0.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn0.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._depthwise_conv.weight: copying a param with shape torch.Size([720, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.13._bn1.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn1.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn1.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn1.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._se_reduce.weight: copying a param with shape torch.Size([30, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.13._se_reduce.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for model.encoder._blocks.13._se_expand.weight: copying a param with shape torch.Size([720, 30, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for model.encoder._blocks.13._se_expand.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._project_conv.weight: copying a param with shape torch.Size([120, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.13._bn2.weight: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.13._bn2.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.13._bn2.running_mean: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.13._bn2.running_var: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.14._expand_conv.weight: copying a param with shape torch.Size([720, 120, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for model.encoder._blocks.14._bn0.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn0.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn0.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn0.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._depthwise_conv.weight: copying a param with shape torch.Size([720, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.14._bn1.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn1.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn1.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn1.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._se_reduce.weight: copying a param with shape torch.Size([30, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.14._se_reduce.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for model.encoder._blocks.14._se_expand.weight: copying a param with shape torch.Size([720, 30, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for model.encoder._blocks.14._se_expand.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._project_conv.weight: copying a param with shape torch.Size([120, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.14._bn2.weight: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.14._bn2.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.14._bn2.running_mean: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.14._bn2.running_var: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.15._expand_conv.weight: copying a param with shape torch.Size([720, 120, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for model.encoder._blocks.15._bn0.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn0.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn0.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn0.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._depthwise_conv.weight: copying a param with shape torch.Size([720, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.15._bn1.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn1.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn1.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn1.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._se_reduce.weight: copying a param with shape torch.Size([30, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.15._se_reduce.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for model.encoder._blocks.15._se_expand.weight: copying a param with shape torch.Size([720, 30, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for model.encoder._blocks.15._se_expand.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._project_conv.weight: copying a param with shape torch.Size([120, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.15._bn2.weight: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.15._bn2.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.15._bn2.running_mean: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.15._bn2.running_var: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.16._expand_conv.weight: copying a param with shape torch.Size([720, 120, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for model.encoder._blocks.16._bn0.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn0.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn0.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn0.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._depthwise_conv.weight: copying a param with shape torch.Size([720, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.16._bn1.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn1.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn1.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn1.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._se_reduce.weight: copying a param with shape torch.Size([30, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.16._se_reduce.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for model.encoder._blocks.16._se_expand.weight: copying a param with shape torch.Size([720, 30, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for model.encoder._blocks.16._se_expand.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._project_conv.weight: copying a param with shape torch.Size([208, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.16._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.16._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.16._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.16._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.17._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.17._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.17._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.17._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.17._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.17._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._project_conv.weight: copying a param with shape torch.Size([208, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.17._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.17._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.17._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.17._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.18._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.18._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.18._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.18._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.18._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.18._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._project_conv.weight: copying a param with shape torch.Size([208, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.18._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.18._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.18._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.18._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.19._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.19._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.19._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.19._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.19._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.19._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._project_conv.weight: copying a param with shape torch.Size([208, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.19._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.19._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.19._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.19._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.20._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.20._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.20._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.20._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.20._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.20._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._project_conv.weight: copying a param with shape torch.Size([208, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.20._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.20._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.20._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.20._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.21._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.21._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([1152, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.21._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.21._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.21._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.21._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._project_conv.weight: copying a param with shape torch.Size([352, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([320, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.21._bn2.weight: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.21._bn2.bias: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.21._bn2.running_mean: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.21._bn2.running_var: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.22._expand_conv.weight: copying a param with shape torch.Size([2112, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([1920, 320, 1, 1]).\n\tsize mismatch for model.encoder._blocks.22._bn0.weight: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn0.bias: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn0.running_mean: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn0.running_var: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._depthwise_conv.weight: copying a param with shape torch.Size([2112, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([1920, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.22._bn1.weight: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn1.bias: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn1.running_mean: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn1.running_var: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._se_reduce.weight: copying a param with shape torch.Size([88, 2112, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 1920, 1, 1]).\n\tsize mismatch for model.encoder._blocks.22._se_reduce.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.22._se_expand.weight: copying a param with shape torch.Size([2112, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([1920, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.22._se_expand.bias: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._project_conv.weight: copying a param with shape torch.Size([352, 2112, 1, 1]) from checkpoint, the shape in current model is torch.Size([320, 1920, 1, 1]).\n\tsize mismatch for model.encoder._blocks.22._bn2.weight: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.22._bn2.bias: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.22._bn2.running_mean: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.22._bn2.running_var: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._conv_head.weight: copying a param with shape torch.Size([1408, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280, 320, 1, 1]).\n\tsize mismatch for model.encoder._bn1.weight: copying a param with shape torch.Size([1408]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for model.encoder._bn1.bias: copying a param with shape torch.Size([1408]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for model.encoder._bn1.running_mean: copying a param with shape torch.Size([1408]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for model.encoder._bn1.running_var: copying a param with shape torch.Size([1408]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for model.decoder.blocks.0.conv1.0.weight: copying a param with shape torch.Size([256, 472, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 432, 3, 3]).\n\tsize mismatch for model.decoder.blocks.1.conv1.0.weight: copying a param with shape torch.Size([128, 304, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 296, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m lit_model \u001b[38;5;241m=\u001b[39m UNET_TILE_lit(\n\u001b[1;32m      2\u001b[0m         use_wandb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m         z_dim \u001b[38;5;241m=\u001b[39m Z_DIM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m,\n\u001b[1;32m     11\u001b[0m         gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.85\u001b[39m,)\n\u001b[0;32m---> 14\u001b[0m lit_model \u001b[38;5;241m=\u001b[39m \u001b[43mlit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHECKPOINT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43msw_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     20\u001b[0m lit_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1531\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1459\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1531\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:90\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:149\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m strict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mmissing_keys:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNET_TILE_lit:\n\tUnexpected key(s) in state_dict: \"loss_bce.pos_weight\". \n\tsize mismatch for model.encoder._blocks.5._project_conv.weight: copying a param with shape torch.Size([48, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 144, 1, 1]).\n\tsize mismatch for model.encoder._blocks.5._bn2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.5._bn2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.5._bn2.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.5._bn2.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.6._expand_conv.weight: copying a param with shape torch.Size([288, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for model.encoder._blocks.6._bn0.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn0.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn0.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn0.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._depthwise_conv.weight: copying a param with shape torch.Size([288, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([240, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.6._bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._se_reduce.weight: copying a param with shape torch.Size([12, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.6._se_reduce.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for model.encoder._blocks.6._se_expand.weight: copying a param with shape torch.Size([288, 12, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for model.encoder._blocks.6._se_expand.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.6._project_conv.weight: copying a param with shape torch.Size([48, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.6._bn2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.6._bn2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.6._bn2.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.6._bn2.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.7._expand_conv.weight: copying a param with shape torch.Size([288, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for model.encoder._blocks.7._bn0.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn0.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn0.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn0.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._depthwise_conv.weight: copying a param with shape torch.Size([288, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([240, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.7._bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._se_reduce.weight: copying a param with shape torch.Size([12, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.7._se_reduce.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for model.encoder._blocks.7._se_expand.weight: copying a param with shape torch.Size([288, 12, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for model.encoder._blocks.7._se_expand.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.7._project_conv.weight: copying a param with shape torch.Size([48, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.7._bn2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.7._bn2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.7._bn2.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.7._bn2.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for model.encoder._blocks.8._expand_conv.weight: copying a param with shape torch.Size([288, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for model.encoder._blocks.8._bn0.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn0.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn0.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn0.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._depthwise_conv.weight: copying a param with shape torch.Size([288, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.8._bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._se_reduce.weight: copying a param with shape torch.Size([12, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.8._se_reduce.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for model.encoder._blocks.8._se_expand.weight: copying a param with shape torch.Size([288, 12, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for model.encoder._blocks.8._se_expand.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for model.encoder._blocks.8._project_conv.weight: copying a param with shape torch.Size([88, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 240, 1, 1]).\n\tsize mismatch for model.encoder._blocks.8._bn2.weight: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.8._bn2.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.8._bn2.running_mean: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.8._bn2.running_var: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.9._expand_conv.weight: copying a param with shape torch.Size([528, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.9._bn0.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn0.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn0.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn0.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._depthwise_conv.weight: copying a param with shape torch.Size([528, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.9._bn1.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn1.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn1.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._bn1.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._se_reduce.weight: copying a param with shape torch.Size([22, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.9._se_reduce.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for model.encoder._blocks.9._se_expand.weight: copying a param with shape torch.Size([528, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for model.encoder._blocks.9._se_expand.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.9._project_conv.weight: copying a param with shape torch.Size([88, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.9._bn2.weight: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.9._bn2.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.9._bn2.running_mean: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.9._bn2.running_var: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.10._expand_conv.weight: copying a param with shape torch.Size([528, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.10._bn0.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn0.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn0.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn0.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._depthwise_conv.weight: copying a param with shape torch.Size([528, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.10._bn1.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn1.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn1.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._bn1.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._se_reduce.weight: copying a param with shape torch.Size([22, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.10._se_reduce.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for model.encoder._blocks.10._se_expand.weight: copying a param with shape torch.Size([528, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for model.encoder._blocks.10._se_expand.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.10._project_conv.weight: copying a param with shape torch.Size([88, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.10._bn2.weight: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.10._bn2.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.10._bn2.running_mean: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.10._bn2.running_var: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.11._expand_conv.weight: copying a param with shape torch.Size([528, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.11._bn0.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn0.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn0.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn0.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._depthwise_conv.weight: copying a param with shape torch.Size([528, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.11._bn1.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn1.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn1.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._bn1.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._se_reduce.weight: copying a param with shape torch.Size([22, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.11._se_reduce.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for model.encoder._blocks.11._se_expand.weight: copying a param with shape torch.Size([528, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for model.encoder._blocks.11._se_expand.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.11._project_conv.weight: copying a param with shape torch.Size([88, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.11._bn2.weight: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.11._bn2.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.11._bn2.running_mean: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.11._bn2.running_var: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.12._expand_conv.weight: copying a param with shape torch.Size([528, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.12._bn0.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn0.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn0.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn0.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._depthwise_conv.weight: copying a param with shape torch.Size([528, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([480, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.12._bn1.weight: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn1.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn1.running_mean: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._bn1.running_var: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._se_reduce.weight: copying a param with shape torch.Size([22, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.12._se_reduce.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for model.encoder._blocks.12._se_expand.weight: copying a param with shape torch.Size([528, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for model.encoder._blocks.12._se_expand.bias: copying a param with shape torch.Size([528]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for model.encoder._blocks.12._project_conv.weight: copying a param with shape torch.Size([120, 528, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 480, 1, 1]).\n\tsize mismatch for model.encoder._blocks.12._bn2.weight: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.12._bn2.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.12._bn2.running_mean: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.12._bn2.running_var: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.13._expand_conv.weight: copying a param with shape torch.Size([720, 120, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for model.encoder._blocks.13._bn0.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn0.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn0.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn0.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._depthwise_conv.weight: copying a param with shape torch.Size([720, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.13._bn1.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn1.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn1.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._bn1.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._se_reduce.weight: copying a param with shape torch.Size([30, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.13._se_reduce.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for model.encoder._blocks.13._se_expand.weight: copying a param with shape torch.Size([720, 30, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for model.encoder._blocks.13._se_expand.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.13._project_conv.weight: copying a param with shape torch.Size([120, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.13._bn2.weight: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.13._bn2.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.13._bn2.running_mean: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.13._bn2.running_var: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.14._expand_conv.weight: copying a param with shape torch.Size([720, 120, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for model.encoder._blocks.14._bn0.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn0.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn0.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn0.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._depthwise_conv.weight: copying a param with shape torch.Size([720, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.14._bn1.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn1.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn1.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._bn1.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._se_reduce.weight: copying a param with shape torch.Size([30, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.14._se_reduce.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for model.encoder._blocks.14._se_expand.weight: copying a param with shape torch.Size([720, 30, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for model.encoder._blocks.14._se_expand.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.14._project_conv.weight: copying a param with shape torch.Size([120, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.14._bn2.weight: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.14._bn2.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.14._bn2.running_mean: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.14._bn2.running_var: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.15._expand_conv.weight: copying a param with shape torch.Size([720, 120, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for model.encoder._blocks.15._bn0.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn0.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn0.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn0.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._depthwise_conv.weight: copying a param with shape torch.Size([720, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.15._bn1.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn1.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn1.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._bn1.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._se_reduce.weight: copying a param with shape torch.Size([30, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.15._se_reduce.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for model.encoder._blocks.15._se_expand.weight: copying a param with shape torch.Size([720, 30, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for model.encoder._blocks.15._se_expand.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.15._project_conv.weight: copying a param with shape torch.Size([120, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.15._bn2.weight: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.15._bn2.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.15._bn2.running_mean: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.15._bn2.running_var: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for model.encoder._blocks.16._expand_conv.weight: copying a param with shape torch.Size([720, 120, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for model.encoder._blocks.16._bn0.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn0.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn0.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn0.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._depthwise_conv.weight: copying a param with shape torch.Size([720, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.16._bn1.weight: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn1.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn1.running_mean: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._bn1.running_var: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._se_reduce.weight: copying a param with shape torch.Size([30, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.16._se_reduce.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for model.encoder._blocks.16._se_expand.weight: copying a param with shape torch.Size([720, 30, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for model.encoder._blocks.16._se_expand.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for model.encoder._blocks.16._project_conv.weight: copying a param with shape torch.Size([208, 720, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 672, 1, 1]).\n\tsize mismatch for model.encoder._blocks.16._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.16._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.16._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.16._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.17._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.17._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.17._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.17._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.17._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.17._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.17._project_conv.weight: copying a param with shape torch.Size([208, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.17._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.17._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.17._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.17._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.18._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.18._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.18._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.18._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.18._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.18._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.18._project_conv.weight: copying a param with shape torch.Size([208, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.18._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.18._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.18._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.18._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.19._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.19._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.19._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.19._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.19._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.19._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.19._project_conv.weight: copying a param with shape torch.Size([208, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.19._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.19._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.19._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.19._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.20._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.20._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for model.encoder._blocks.20._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.20._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.20._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.20._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.20._project_conv.weight: copying a param with shape torch.Size([208, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.20._bn2.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.20._bn2.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.20._bn2.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.20._bn2.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for model.encoder._blocks.21._expand_conv.weight: copying a param with shape torch.Size([1248, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for model.encoder._blocks.21._bn0.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn0.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn0.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn0.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._depthwise_conv.weight: copying a param with shape torch.Size([1248, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([1152, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.21._bn1.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn1.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn1.running_mean: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._bn1.running_var: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._se_reduce.weight: copying a param with shape torch.Size([52, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.21._se_reduce.bias: copying a param with shape torch.Size([52]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for model.encoder._blocks.21._se_expand.weight: copying a param with shape torch.Size([1248, 52, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for model.encoder._blocks.21._se_expand.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for model.encoder._blocks.21._project_conv.weight: copying a param with shape torch.Size([352, 1248, 1, 1]) from checkpoint, the shape in current model is torch.Size([320, 1152, 1, 1]).\n\tsize mismatch for model.encoder._blocks.21._bn2.weight: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.21._bn2.bias: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.21._bn2.running_mean: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.21._bn2.running_var: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.22._expand_conv.weight: copying a param with shape torch.Size([2112, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([1920, 320, 1, 1]).\n\tsize mismatch for model.encoder._blocks.22._bn0.weight: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn0.bias: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn0.running_mean: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn0.running_var: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._depthwise_conv.weight: copying a param with shape torch.Size([2112, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([1920, 1, 3, 3]).\n\tsize mismatch for model.encoder._blocks.22._bn1.weight: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn1.bias: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn1.running_mean: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._bn1.running_var: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._se_reduce.weight: copying a param with shape torch.Size([88, 2112, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 1920, 1, 1]).\n\tsize mismatch for model.encoder._blocks.22._se_reduce.bias: copying a param with shape torch.Size([88]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for model.encoder._blocks.22._se_expand.weight: copying a param with shape torch.Size([2112, 88, 1, 1]) from checkpoint, the shape in current model is torch.Size([1920, 80, 1, 1]).\n\tsize mismatch for model.encoder._blocks.22._se_expand.bias: copying a param with shape torch.Size([2112]) from checkpoint, the shape in current model is torch.Size([1920]).\n\tsize mismatch for model.encoder._blocks.22._project_conv.weight: copying a param with shape torch.Size([352, 2112, 1, 1]) from checkpoint, the shape in current model is torch.Size([320, 1920, 1, 1]).\n\tsize mismatch for model.encoder._blocks.22._bn2.weight: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.22._bn2.bias: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.22._bn2.running_mean: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._blocks.22._bn2.running_var: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for model.encoder._conv_head.weight: copying a param with shape torch.Size([1408, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280, 320, 1, 1]).\n\tsize mismatch for model.encoder._bn1.weight: copying a param with shape torch.Size([1408]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for model.encoder._bn1.bias: copying a param with shape torch.Size([1408]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for model.encoder._bn1.running_mean: copying a param with shape torch.Size([1408]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for model.encoder._bn1.running_var: copying a param with shape torch.Size([1408]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for model.decoder.blocks.0.conv1.0.weight: copying a param with shape torch.Size([256, 472, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 432, 3, 3]).\n\tsize mismatch for model.decoder.blocks.1.conv1.0.weight: copying a param with shape torch.Size([128, 304, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 296, 3, 3])."
     ]
    }
   ],
   "source": [
    "lit_model = UNET_TILE_lit(\n",
    "        use_wandb = False,\n",
    "        z_dim = Z_DIM,\n",
    "        patch_size = (PATCH_SIZE,PATCH_SIZE),\n",
    "        sw_batch_size=8 ,\n",
    "        eta_min = 1e-7,\n",
    "        t_max = 120,\n",
    "        max_epochs = 1000,\n",
    "        weight_decay =  1e-6,\n",
    "        learning_rate = 0.0001,\n",
    "        gamma = 0.85,)\n",
    "\n",
    "\n",
    "lit_model = lit_model.load_from_checkpoint(CHECKPOINT, \n",
    "                                           patch_size = (PATCH_SIZE,PATCH_SIZE),\n",
    "                                           use_wandb=False,\n",
    "                                          sw_batch_size = 4,\n",
    "                                          ).to(DEVICE)\n",
    "\n",
    "lit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ccfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_dataset(fragment_id):\n",
    "    test_images = read_image(fragment_id)\n",
    "    \n",
    "    x1_list = list(range(0, test_images.shape[1]-CFG.patch_size+1, CFG.stride))\n",
    "    y1_list = list(range(0, test_images.shape[0]-CFG.patch_size+1, CFG.stride))\n",
    "    \n",
    "    test_images_list = []\n",
    "    xyxys = []\n",
    "    for y1 in y1_list:\n",
    "        for x1 in x1_list:\n",
    "            y2 = y1 + CFG.patch_size\n",
    "            x2 = x1 + CFG.patch_size\n",
    "            \n",
    "            test_images_list.append(test_images[y1:y2, x1:x2])\n",
    "            xyxys.append((x1, y1, x2, y2))\n",
    "    xyxys = np.stack(xyxys)\n",
    "            \n",
    "    test_dataset = CustomDataset(test_images_list, CFG, transform=get_transforms(data='valid', cfg=CFG))\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=CFG.batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=CFG.num_workers, pin_memory=False, drop_last=False)\n",
    "    \n",
    "    return test_loader, xyxys\n",
    "\n",
    "\n",
    "def get_transforms(data, cfg):\n",
    "    return A.Compose(\n",
    "        [\n",
    "        A.Resize(PATCH_SIZE, PATCH_SIZE),\n",
    "        A.Normalize(\n",
    "            mean=[0] * Z_DIM,\n",
    "            std=[1] * Z_DIM\n",
    "        ),\n",
    "\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "def read_image(fragment_id):\n",
    "    images = []\n",
    "\n",
    "    # idxs = range(65)\n",
    "    mid = 65 // 2\n",
    "    start = mid - CFG.z_dim // 2\n",
    "    end = mid + CFG.z_dim // 2\n",
    "    idxs = range(start, end)\n",
    "\n",
    "    for i in tqdm(idxs):\n",
    "        \n",
    "        image = cv2.imread(COMPETITION_DATA_DIR_str + f\"test/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n",
    "\n",
    "        pad0 = (CFG.patch_size - image.shape[0] % CFG.patch_size)\n",
    "        pad1 = (CFG.patch_size - image.shape[1] % CFG.patch_size)\n",
    "\n",
    "        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "        images.append(image)\n",
    "    images = np.stack(images, axis=2)\n",
    "    \n",
    "    return images\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, cfg, labels=None, transform=None):\n",
    "        self.images = images\n",
    "        self.cfg = cfg\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.xyxys)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # x1, y1, x2, y2 = self.xyxys[idx]\n",
    "        image = self.images[idx]\n",
    "        data = self.transform(image=image)\n",
    "        image = data['image']\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    \n",
    "def rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    # pixels = (pixels >= thr).astype(int)\n",
    "    \n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD =0.4\n",
    "results = []\n",
    "for fragment_id in CFG.test_fragment_ids:\n",
    "    \n",
    "    test_loader, xyxys = make_test_dataset(fragment_id)\n",
    "    \n",
    "    binary_mask = cv2.imread(COMPETITION_DATA_DIR_str + f\"test/{fragment_id}/mask.png\", 0)\n",
    "    binary_mask = (binary_mask / 255).astype(int)\n",
    "    binary_mask = torch.tensor(binary_mask)#.to(DEVICE)\n",
    "    \n",
    "    ori_h = binary_mask.shape[0]\n",
    "    ori_w = binary_mask.shape[1]\n",
    "    # mask = mask / 255\n",
    "\n",
    "    pad0 = (CFG.patch_size - binary_mask.shape[0] % CFG.patch_size)\n",
    "    pad1 = (CFG.patch_size - binary_mask.shape[1] % CFG.patch_size)\n",
    "\n",
    "    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "    \n",
    "    mask_pred = torch.zeros(binary_mask.shape).to(DEVICE)\n",
    "    mask_count = torch.zeros(binary_mask.shape).to(DEVICE)\n",
    "\n",
    "    for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        images = images.to(DEVICE)\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_preds = lit_model(images)\n",
    "            #y_preds = y_preds.numpy()\n",
    "            #print(type(y_preds))\n",
    "\n",
    "        start_idx = step*CFG.batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        #xyxys = torch.from_numpy(xyxys)\n",
    "        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n",
    "            mask_count[y1:y2, x1:x2] += torch.ones((CFG.patch_size, CFG.patch_size)).to(DEVICE)\n",
    "    \n",
    "    plt.imshow(mask_count.to('cpu'))\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'mask_count_min: {mask_count.min()}')\n",
    "    mask_pred /= mask_count\n",
    "    \n",
    "    mask_pred = mask_pred[:ori_h, :ori_w]\n",
    "    binary_mask = binary_mask[:ori_h, :ori_w]\n",
    "    \n",
    "    mask_pred = mask_pred.to('cpu').numpy()\n",
    "    mask_pred = (mask_pred >= THRESHOLD).astype(int)\n",
    "    mask_pred *= binary_mask\n",
    "    \n",
    "    plt.imshow(mask_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    inklabels_rle = rle(mask_pred)\n",
    "    \n",
    "    results.append( inklabels_rle)\n",
    "    \n",
    "\n",
    "    del mask_pred, mask_count\n",
    "    del test_loader\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeee642",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD =0.5\n",
    "results = []\n",
    "preds = []\n",
    "for fragment_id in CFG.test_fragment_ids:\n",
    "    \n",
    "    test_loader, xyxys = make_test_dataset(fragment_id)\n",
    "    \n",
    "    binary_mask = cv2.imread(COMPETITION_DATA_DIR_str + f\"test/{fragment_id}/mask.png\", 0)\n",
    "    binary_mask = (binary_mask / 255).astype(int)\n",
    "    binary_mask = torch.tensor(binary_mask)#.to(DEVICE)\n",
    "    \n",
    "    ori_h = binary_mask.shape[0]\n",
    "    ori_w = binary_mask.shape[1]\n",
    "    # mask = mask / 255\n",
    "\n",
    "    pad0 = (CFG.patch_size - binary_mask.shape[0] % CFG.patch_size)\n",
    "    pad1 = (CFG.patch_size - binary_mask.shape[1] % CFG.patch_size)\n",
    "\n",
    "    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "    \n",
    "    mask_pred = torch.zeros(binary_mask.shape).to(DEVICE)\n",
    "    mask_count = torch.zeros(binary_mask.shape).to(DEVICE)\n",
    "\n",
    "    for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        images = images.to(DEVICE)\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_preds = lit_model(images)\n",
    "            #y_preds = y_preds.numpy()\n",
    "            #print(type(y_preds))\n",
    "\n",
    "        start_idx = step*CFG.batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        #xyxys = torch.from_numpy(xyxys)\n",
    "        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n",
    "            mask_count[y1:y2, x1:x2] += torch.ones((CFG.patch_size, CFG.patch_size)).to(DEVICE)\n",
    "    \n",
    "    plt.imshow(mask_count.to('cpu'))\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'mask_count_min: {mask_count.min()}')\n",
    "    mask_pred /= mask_count\n",
    "    \n",
    "    mask_pred = mask_pred[:ori_h, :ori_w]\n",
    "    binary_mask = binary_mask[:ori_h, :ori_w]\n",
    "    \n",
    "    mask_pred = mask_pred.to('cpu').numpy()\n",
    "    mask_pred = (mask_pred >= THRESHOLD).astype(int)\n",
    "    mask_pred *= binary_mask\n",
    "    \n",
    "    plt.imshow(mask_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    inklabels_rle = rle(mask_pred)\n",
    "    \n",
    "    results.append( inklabels_rle)\n",
    "    \n",
    "\n",
    "    del mask_pred, mask_count\n",
    "    del test_loader\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffb7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13b48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
