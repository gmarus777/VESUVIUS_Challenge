{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38a6399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge/jupyter notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "# Make sure root project directory is named 'VESUVIUS_Challenge' for this to work\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-18:] == 'VESUVIUS_Challenge':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in the root folder of the project\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d9e846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 17:25:11,379 - Created a temporary directory at /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp_bd34186\n",
      "2023-05-17 17:25:11,380 - Writing /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp_bd34186/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, List\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from Data_Modules.Vesuvius_Dataset import Vesuvius_Tile_Datamodule\n",
    "from lit_models.Vesuvius_Lit_Model import Lit_Model\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn\n",
    "from Models.PVT2 import PyramidVisionTransformerV2, Up, OutConv\n",
    "from Models.Mixed_Vision_Trans import MixVisionTransformer\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from Models.Swin import SwinTransformer, SwinTransformerBlockV2, PatchMergingV2\n",
    "from lit_models.Loss_functions import ComboBCEDiceLoss, TverskyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b30e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "Z_DIM = 8\n",
    "COMPETITION_DATA_DIR_str =  \"kaggle/input/vesuvius-challenge-ink-detection/\"\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "# change to the line below if not using Apple's M1 or chips\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58e7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixed_w_UNet(nn.Module):\n",
    "    def __init__(self, in_channels,  embed_dims=[ 64, 128, 256, 512], n_classes=1, ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dims = embed_dims\n",
    "        \n",
    "        self.pvt = MixVisionTransformer(img_size = PATCH_SIZE,\n",
    "                                  patch_size = 4,\n",
    "                                  in_chans = Z_DIM,\n",
    "                                  num_classes = 1,\n",
    "                                  embed_dims = embed_dims,\n",
    "                                num_heads=[1, 2, 4, 8],\n",
    "                                  mlp_ratios=[4, 4, 4, 4],\n",
    "                                  qkv_bias=True,\n",
    "                                  qk_scale=None,\n",
    "                                  drop_rate=0.,\n",
    "                                attn_drop_rate=0.,\n",
    "                                  drop_path_rate=0.1,\n",
    "                                  norm_layer=partial(nn.LayerNorm, eps=1e-3),\n",
    "                                #norm_layer=nn.LayerNorm,  \n",
    "                                  depths=[2, 2, 2, 2],\n",
    "                                  sr_ratios=[8, 4, 2, 1]\n",
    "                                 ) \n",
    "        \n",
    "        self.up1 = Up(self.embed_dims[-1], self.embed_dims[-2])\n",
    "        self.up2 = Up(self.embed_dims[-2], self.embed_dims[-3])\n",
    "        self.up3 = Up(self.embed_dims[-3], self.embed_dims[-4])\n",
    "        self.up4 = Up(self.embed_dims[-4], in_channels, last_layer = True)\n",
    "        \n",
    "        self.out_conv = OutConv(in_channels,n_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2, x3, x4, x5 = self.pvt(x)\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.out_conv(x)\n",
    "        \n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7028b54b",
   "metadata": {},
   "source": [
    "dummy = torch.randn(16,8,256,256)\n",
    "dummy_y = torch.ones(16,1,256,256)\n",
    "test_model = Mixed_w_UNet(in_channels = 8)\n",
    "outputs = test_model(dummy)\n",
    "loss_bce = smp.losses.SoftBCEWithLogitsLoss(  pos_weight=torch.tensor(0.5))\n",
    "loss_tversky = smp.losses.TverskyLoss(mode='binary',\n",
    "                                                   classes=None,\n",
    "                                                   log_loss=False,\n",
    "                                                   from_logits=False,\n",
    "                                                   alpha=0.5,\n",
    "                                                   beta=0.5,\n",
    "                                                   gamma=1.0,\n",
    "                                                   smooth=0,\n",
    "                                                   ignore_index=None,\n",
    "                                                   eps=1e-06,\n",
    "                                                   )\n",
    "\n",
    "\n",
    "combo_loss = ComboBCEDiceLoss( use_running_mean=False,\n",
    "                              bce_weight=1, \n",
    "                              dice_weight=1,\n",
    "                              eps=1e-6, gamma=0.9, combined_loss_only=True)\n",
    "\n",
    "\n",
    "loss_tver_custom = TverskyLoss( alpha=0.5, beta=0.5, eps=1e-7,)\n",
    "\n",
    "\n",
    "loss = loss_bce(outputs, dummy_y.float())\n",
    "loss_t = loss_tversky(outputs, dummy_y.float())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91febfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53112575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CFG:\n",
    "    \n",
    "    device = DEVICE\n",
    "    \n",
    "    THRESHOLD = 0.4\n",
    "    use_wandb = True\n",
    "    \n",
    "    ######### Dataset #########\n",
    "    \n",
    "    # stage: 'train' or 'test'\n",
    "    stage = 'train' \n",
    "    \n",
    "    # location of competition Data\n",
    "    competition_data_dir = COMPETITION_DATA_DIR_str\n",
    "    \n",
    "    # Number of slices in z-dim: 1<z_dim<65\n",
    "    z_dim = Z_DIM\n",
    "    \n",
    "    # fragments to use for training avalaible [1,2,3]\n",
    "    train_fragment_id=[2,3]\n",
    "    \n",
    "    # fragments to use for validation\n",
    "    val_fragment_id=[1]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    batch_size = 16\n",
    "    \n",
    "    # Size of the patch and stride for feeding the model\n",
    "    patch_size = PATCH_SIZE\n",
    "    stride = patch_size // 2\n",
    "    \n",
    "    \n",
    "    num_workers = 0\n",
    "    on_gpu = True\n",
    "    \n",
    "    \n",
    "    ######## Model and Lightning Model paramters ############\n",
    "    \n",
    "    # MODEL\n",
    "    model = Mixed_w_UNet(in_channels = z_dim)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    checkpoint = None\n",
    "    save_directory = None\n",
    "    \n",
    "    \n",
    "    accumulate_grad_batches = 128 // batch_size  # experiments showed batch_size * accumulate_grad = 192 is optimal\n",
    "    learning_rate = 0.0001\n",
    "    eta_min = 1e-8\n",
    "    t_max = 80\n",
    "    max_epochs = 120\n",
    "    weight_decay =  0.0001\n",
    "    precision =16\n",
    "    \n",
    "    # checkpointing\n",
    "    save_top_k=5\n",
    "    \n",
    "    monitor=\"FBETA\"\n",
    "    mode=\"max\"\n",
    "    \n",
    "    \n",
    "    ####### Augemtnations ###############\n",
    "    \n",
    "    # Training Aug\n",
    "    train_transforms = [\n",
    "        # A.RandomResizedCrop(\n",
    "        #     size, size, scale=(0.85, 1.0)),\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        \n",
    "       \n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.CoarseDropout(max_holes=1, max_width=int(patch_size * 0.3), max_height=int(patch_size * 0.3), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        # A.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Validaiton Aug\n",
    "    val_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "    # Test Aug\n",
    "    test_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean=[0] * z_dim,\n",
    "            std=[1] * z_dim\n",
    "        ),\n",
    "\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c4d6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422ada664c7d47eeb78fef8a2b3747f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4556540fada34360bf76c89e2fe1e602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9138ac7d71d48359db4ab936ec39716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Vesuvius_Tile_Datamodule(cfg=CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38eea270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgmarus\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gregory/PROJECT_ML/VESUVIUS_Challenge/wandb/run-20230517_172524-yyxi7itv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/yyxi7itv' target=\"_blank\">legendary-field-604</a></strong> to <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge' target=\"_blank\">https://wandb.ai/gmarus/VESUVIUS_Challenge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/yyxi7itv' target=\"_blank\">https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/yyxi7itv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lit_model = Lit_Model(cfg=CFG,)\n",
    "\n",
    "Checkpoint = False\n",
    "if Checkpoint:\n",
    "    lit_model = lit_model.load_from_checkpoint('logs/gcp_checkpoints/MoUB4_Bce015_Tver_alpha085epoch_64.ckpt',\n",
    "                                               #learning_rate =7e-6 ,\n",
    "                                                #t_max = 70,\n",
    "                                               #eta_min = 1e-8,\n",
    "                                               #weight_decay =  0.0001,\n",
    "                                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e025eedb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 17:25:28,065 - Using 16bit None Automatic Mixed Precision (AMP)\n",
      "2023-05-17 17:25:28,077 - GPU available: True (mps), used: True\n",
      "2023-05-17 17:25:28,078 - TPU available: False, using: 0 TPU cores\n",
      "2023-05-17 17:25:28,078 - IPU available: False, using: 0 IPUs\n",
      "2023-05-17 17:25:28,079 - HPU available: False, using: 0 HPUs\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2023-05-17 17:25:28,234 - \n",
      "  | Name                  | Type                  | Params\n",
      "----------------------------------------------------------------\n",
      "0 | metrics               | ModuleDict            | 0     \n",
      "1 | model                 | Mixed_w_UNet          | 14.6 M\n",
      "2 | loss_tversky          | TverskyLoss           | 0     \n",
      "3 | loss_focal            | FocalLoss             | 0     \n",
      "4 | loss_bce              | SoftBCEWithLogitsLoss | 0     \n",
      "5 | loss_monai_focal_dice | DiceFocalLoss         | 0     \n",
      "----------------------------------------------------------------\n",
      "14.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 M    Total params\n",
      "29.272    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:221: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/segmentation_models_pytorch/metrics/functional.py:214: UserWarning: MPS: no support for int64 for sum_out_mps, downcasting to a smaller data type (int32/float32). Native support for int64 has been added in macOS 13.3. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1681456119295/work/aten/src/ATen/native/mps/operations/ReduceOps.mm:132.)\n",
      "  tp = (output * target).sum(2)\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/torchmetrics/utilities/checks.py:57: UserWarning: MPS: no support for int64 for min_max, downcasting to a smaller data type (int32/float32). Native support for int64 has been added in macOS 13.3. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1681456119295/work/aten/src/ATen/native/mps/operations/ReduceOps.mm:610.)\n",
      "  if ignore_index is None and target.min() < 0:\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38800d577d544ff6a3f265c39107cee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9961e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = 'logs/MixedTr_Unet_Bce50_tver_alpha70_gamma1_256_8'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=5,\n",
    "    monitor=\"FBETA\",\n",
    "    mode=\"max\",\n",
    "    dirpath=SAVE_DIR,\n",
    "    filename=\"MixedTr_Unet_Bce50_tver_alpha70_gamma1_256_8{epoch:02d}{FBETA:.2f}{val_loss:.2f}{fbeta_4:.2f}{recall:.2f}{precision:.2f}\",\n",
    "    save_last =True,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        accelerator='mps',\n",
    "        #benchmark=True,\n",
    "        max_epochs=CFG.max_epochs,\n",
    "        check_val_every_n_epoch= 1,\n",
    "        devices=1,\n",
    "        #fast_dev_run=False,\n",
    "        logger=pl.loggers.CSVLogger(save_dir=SAVE_DIR),\n",
    "        log_every_n_steps=1,\n",
    "        default_root_dir = SAVE_DIR,\n",
    "        #overfit_batches=1,\n",
    "        #precision=CFG.precision,\n",
    "        accumulate_grad_batches=CFG.accumulate_grad_batches, \n",
    "        callbacks=[checkpoint_callback],\n",
    "        gradient_clip_val=1,\n",
    "        #resume_from_checkpoint ='logs/gcp_checkpoints/MoUB4_Bce015_Tver_alpha085epoch_64.ckpt'\n",
    "        #detect_anomaly=True,\n",
    "        \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer.fit(lit_model, datamodule=dataset,\n",
    "            #ckpt_path='logs/gcp_checkpoints/MoUB4_Bce015_Tver_alpha085epoch_64.ckpt'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256eb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
