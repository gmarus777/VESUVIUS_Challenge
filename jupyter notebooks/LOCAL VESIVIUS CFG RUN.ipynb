{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da93a95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge/jupyter notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "# Make sure root project directory is named 'VESUVIUS_Challenge' for this to work\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-18:] == 'VESUVIUS_Challenge':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in the root folder of the project\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869e23d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-14 18:16:16,793 - Created a temporary directory at /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp27eqsoei\n",
      "2023-05-14 18:16:16,794 - Writing /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp27eqsoei/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai\n",
    "from monai.visualize import matshow3d\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, List\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from Data_Modules.Vesuvius_Dataset import Vesuvius_Tile_Datamodule\n",
    "from lit_models.Vesuvius_Lit_Model import Lit_Model\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5951ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "Z_DIM = 16\n",
    "COMPETITION_DATA_DIR_str =  \"kaggle/input/vesuvius-challenge-ink-detection/\"\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "# change to the line below if not using Apple's M1 or chips\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b1701",
   "metadata": {},
   "source": [
    "'''\n",
    "smp.DeepLabV3Plus(encoder_name='efficientnet-b3',\n",
    "                          encoder_depth=5,\n",
    "                          encoder_weights='imagenet',\n",
    "                        encoder_output_stride=16,\n",
    "                             decoder_channels=256,\n",
    "                             decoder_atrous_rates=(12, 24, 36),\n",
    "                             in_channels=16,\n",
    "                             classes=1,\n",
    "                             activation=None,\n",
    "                             upsampling=4,\n",
    "                             aux_params=None)\n",
    "\n",
    "'''\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.pre_model = Convolution3d\n",
    "        \n",
    "        self.model = smp.DeepLabV3Plus(encoder_name='efficientnet-b3',\n",
    "                          encoder_depth=5,\n",
    "                          encoder_weights='imagenet',\n",
    "                        encoder_output_stride=16,\n",
    "                             decoder_channels=256,\n",
    "                             decoder_atrous_rates=(12, 24, 36),\n",
    "                             in_channels=16,\n",
    "                             classes=1,\n",
    "                             activation=None,\n",
    "                             upsampling=4,\n",
    "                             aux_params=None)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.premodel(x)\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class Convolution3d(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184da1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.pre_model =monai.networks.nets.UNet(\n",
    "                                        spatial_dims=2,\n",
    "                                        in_channels=16,\n",
    "                                        out_channels=3,\n",
    "                                        channels=( 32, 64,128,),\n",
    "                                        strides=(2, 2, ),\n",
    "                                        num_res_units=2,\n",
    "                                        dropout=0,\n",
    "                                        norm='instance',\n",
    "                                        bias =False,\n",
    "\n",
    "                                    )\n",
    "        \n",
    "        self.model =monai.networks.nets.ViTAutoEnc(in_channels=16,\n",
    "                                                   img_size = (256,256),\n",
    "                                                   patch_size = (16,16),\n",
    "                                                   out_channels=1,\n",
    "                                                   deconv_chns=16,\n",
    "                                                   hidden_size=768,\n",
    "                                                   mlp_dim=3072, \n",
    "                                                   num_layers=12, \n",
    "                                                   num_heads=12,\n",
    "                                                   pos_embed='conv',\n",
    "                                                   dropout_rate=0.0,\n",
    "                                                   spatial_dims=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.pre_model(x)\n",
    "        x = x.squeeze(1)\n",
    "        out = self.model(x)\n",
    "        return out[0]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e48824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CFG:\n",
    "    \n",
    "    device = DEVICE\n",
    "    \n",
    "    THRESHOLD = 0.4\n",
    "    use_wandb = True\n",
    "    \n",
    "    ######### Dataset #########\n",
    "    \n",
    "    # stage: 'train' or 'test'\n",
    "    stage = 'train' \n",
    "    \n",
    "    # location of competition Data\n",
    "    competition_data_dir = COMPETITION_DATA_DIR_str\n",
    "    \n",
    "    # Number of slices in z-dim: 1<z_dim<65\n",
    "    z_dim = Z_DIM\n",
    "    \n",
    "    # fragments to use for training avalaible [1,2,3]\n",
    "    train_fragment_id=[2,3]\n",
    "    \n",
    "    # fragments to use for validation\n",
    "    val_fragment_id=[1]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    batch_size = 4\n",
    "    \n",
    "    # Size of the patch and stride for feeding the model\n",
    "    patch_size = PATCH_SIZE\n",
    "    stride = patch_size // 2\n",
    "    \n",
    "    \n",
    "    num_workers = 0\n",
    "    on_gpu = True\n",
    "    \n",
    "    \n",
    "    ######## Model and Lightning Model paramters ############\n",
    "    \n",
    "    # MODEL\n",
    "    model =Model()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    checkpoint = None\n",
    "    save_directory = None\n",
    "    \n",
    "    \n",
    "    accumulate_grad_batches = 96 // batch_size  # experiments showed batch_size * accumulate_grad = 192 is optimal\n",
    "    learning_rate = 0.0001\n",
    "    eta_min = 1e-8\n",
    "    t_max = 80\n",
    "    max_epochs = 120\n",
    "    weight_decay =  0.0001\n",
    "    precision =16\n",
    "    \n",
    "    # checkpointing\n",
    "    save_top_k=5\n",
    "    \n",
    "    monitor=\"FBETA\"\n",
    "    mode=\"max\"\n",
    "    \n",
    "    \n",
    "    ####### Augemtnations ###############\n",
    "    \n",
    "    # Training Aug\n",
    "    train_transforms = [\n",
    "        # A.RandomResizedCrop(\n",
    "        #     size, size, scale=(0.85, 1.0)),\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        \n",
    "       \n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.CoarseDropout(max_holes=1, max_width=int(patch_size * 0.3), max_height=int(patch_size * 0.3), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        # A.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Validaiton Aug\n",
    "    val_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "    # Test Aug\n",
    "    test_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean=[0] * z_dim,\n",
    "            std=[1] * z_dim\n",
    "        ),\n",
    "\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57787a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47718aadb2844dd0bf03c8feaf05f62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad3eb9bc7c64662b9ac25c7e2829bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed9c873c6e346bc90cebc0999a57249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Vesuvius_Tile_Datamodule(cfg=CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a90f2d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgmarus\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gregory/PROJECT_ML/VESUVIUS_Challenge/wandb/run-20230514_181642-wdbbxjhc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/wdbbxjhc' target=\"_blank\">floral-mountain-521</a></strong> to <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge' target=\"_blank\">https://wandb.ai/gmarus/VESUVIUS_Challenge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/wdbbxjhc' target=\"_blank\">https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/wdbbxjhc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lit_model = Lit_Model(cfg=CFG,)\n",
    "\n",
    "Checkpoint = False\n",
    "if Checkpoint:\n",
    "    lit_model = lit_model.load_from_checkpoint('logs/gcp_checkpoints/MoUB4_Bce015_Tver_alpha085epoch_64.ckpt',\n",
    "                                               #learning_rate =7e-6 ,\n",
    "                                                #t_max = 70,\n",
    "                                               #eta_min = 1e-8,\n",
    "                                               #weight_decay =  0.0001,\n",
    "                                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba62f187",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-14 18:16:46,597 - Using 16bit None Automatic Mixed Precision (AMP)\n",
      "2023-05-14 18:16:46,614 - GPU available: True (mps), used: True\n",
      "2023-05-14 18:16:46,616 - TPU available: False, using: 0 TPU cores\n",
      "2023-05-14 18:16:46,616 - IPU available: False, using: 0 IPUs\n",
      "2023-05-14 18:16:46,617 - HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /Users/gregory/PROJECT_ML/VESUVIUS_Challenge/logs/3D_VITauto_256_16_bce30_tver_alpha80 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2023-05-14 18:16:46,925 - \n",
      "  | Name                  | Type                  | Params\n",
      "----------------------------------------------------------------\n",
      "0 | metrics               | ModuleDict            | 0     \n",
      "1 | model                 | Model                 | 89.0 M\n",
      "2 | loss_dice             | DiceLoss              | 0     \n",
      "3 | loss_tversky          | TverskyLoss           | 0     \n",
      "4 | loss_focal            | FocalLoss             | 0     \n",
      "5 | loss_lovasz           | LovaszLoss            | 0     \n",
      "6 | loss_bce              | SoftBCEWithLogitsLoss | 0     \n",
      "7 | loss_monai_focal_dice | DiceFocalLoss         | 0     \n",
      "----------------------------------------------------------------\n",
      "89.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "89.0 M    Total params\n",
      "177.912   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:221: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/segmentation_models_pytorch/metrics/functional.py:214: UserWarning: MPS: no support for int64 for sum_out_mps, downcasting to a smaller data type (int32/float32). Native support for int64 has been added in macOS 13.3. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1681456119295/work/aten/src/ATen/native/mps/operations/ReduceOps.mm:132.)\n",
      "  tp = (output * target).sum(2)\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/torchmetrics/utilities/checks.py:57: UserWarning: MPS: no support for int64 for min_max, downcasting to a smaller data type (int32/float32). Native support for int64 has been added in macOS 13.3. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1681456119295/work/aten/src/ATen/native/mps/operations/ReduceOps.mm:610.)\n",
      "  if ignore_index is None and target.min() < 0:\n",
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e4da5c5bde4f82bb163b0ec4304445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9961e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9846e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9653e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9384e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9039e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.8619e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.8123e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.6910e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.6194e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5408e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.4551e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.3625e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.2633e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = 'logs/3D_VITauto_256_16_bce30_tver_alpha80'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=5,\n",
    "    monitor=\"FBETA\",\n",
    "    mode=\"max\",\n",
    "    dirpath=SAVE_DIR,\n",
    "    filename=\"3D_VITauto_256_16_bce30_tver_alpha80{epoch:02d}{FBETA:.2f}{val_loss:.2f}{fbeta_4:.2f}{recall:.2f}{precision:.2f}\",\n",
    "    save_last =True,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        accelerator='mps',\n",
    "        #benchmark=True,\n",
    "        max_epochs=CFG.max_epochs,\n",
    "        check_val_every_n_epoch= 1,\n",
    "        devices=1,\n",
    "        #fast_dev_run=fast_dev_run,\n",
    "        logger=pl.loggers.CSVLogger(save_dir=SAVE_DIR),\n",
    "        log_every_n_steps=1,\n",
    "        default_root_dir = SAVE_DIR,\n",
    "        #overfit_batches=1,\n",
    "        precision=CFG.precision,\n",
    "        accumulate_grad_batches=CFG.accumulate_grad_batches, \n",
    "        callbacks=[checkpoint_callback],\n",
    "        #resume_from_checkpoint ='logs/gcp_checkpoints/MoUB4_Bce015_Tver_alpha085epoch_64.ckpt'\n",
    "        \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer.fit(lit_model, datamodule=dataset,\n",
    "            #ckpt_path='logs/gcp_checkpoints/MoUB4_Bce015_Tver_alpha085epoch_64.ckpt'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60ce5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f67db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc554760",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimages\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52604c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec63ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831039e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247a3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
