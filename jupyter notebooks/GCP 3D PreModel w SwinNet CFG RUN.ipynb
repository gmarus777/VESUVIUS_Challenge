{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaeee544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/home/gregorymar577/VESUVIUS_Challenge/jupyter notebooks\n",
      "Current path:/home/gregorymar577/VESUVIUS_Challenge\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "# Make sure root project directory is named 'VESUVIUS_Challenge' for this to work\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-18:] == 'VESUVIUS_Challenge':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in the root folder of the project\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b96769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-10 22:54:03,143 - Created a temporary directory at /tmp/tmpk2e79u5w\n",
      "2023-06-10 22:54:03,144 - Writing /tmp/tmpk2e79u5w/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "#import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, List\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from Data_Modules.Vesuvius_Dataset import Vesuvius_Tile_Datamodule\n",
    "from Data_Modules.Vesuvius_Dataset_w_Mask import Vesuvius_Tile_Datamodule_w_Mask\n",
    "\n",
    "from lit_models.Vesuvius_Lit_Model import Lit_Model\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from lit_models.scratch_models import FPNDecoder\n",
    "from Models.PreBackbone_3D import PreBackbone_3D\n",
    "from Models.PreBackbone_3d_Zdim import PreBackbone_3D_ZDIM\n",
    "from Models.PreBackbone_3d_SIMPLE import PreBackbone_3D_SIMPLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df465a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f2e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 512\n",
    "Z_DIM = 24\n",
    "COMPETITION_DATA_DIR_str =  \"kaggle/input/vesuvius-challenge-ink-detection/\"\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# change to the line below if not using Apple's M1 or chips\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d0ba5",
   "metadata": {},
   "source": [
    "# TRy\n",
    "self.model_2d = smp.Unet(encoder_name='mit_b3',\n",
    "                 encoder_depth=5,\n",
    "                 encoder_weights='imagenet', \n",
    "                 decoder_use_batchnorm=True, \n",
    "                 decoder_channels=(512, 256, 128, 64, 32,),\n",
    "                 decoder_attention_type=None,\n",
    "                 in_channels=3,\n",
    "                 classes=1, activation=None, aux_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71f3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_3dAtt_w_Segformer(nn.Module):\n",
    "    def __init__(self ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_3d =PreBackbone_3D_ZDIM(out_channels = 3,\n",
    "                                           z_dim= Z_DIM, \n",
    "                                           emdedding_dims=[8],\n",
    "                                           filter_sizes=[ 32,64, 128], \n",
    "                                          att_dim =1024,\n",
    "                                          patch_size =PATCH_SIZE).to(DEVICE) \n",
    "        \n",
    "       \n",
    "        self.model_2d = smp.Unet(encoder_name='mit_b4',\n",
    "                                 encoder_depth=5,\n",
    "                                 encoder_weights='imagenet', \n",
    "                                 decoder_use_batchnorm=True, \n",
    "                                 decoder_channels=(512, 256, 128, 64, 32,),\n",
    "                                 decoder_attention_type=None,\n",
    "                                 in_channels=3,\n",
    "                                 classes=1, activation=None, aux_params=None).to(DEVICE) \n",
    "\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        outs_3d = self.model_3d(x)\n",
    "        logits = self.model_2d(outs_3d)\n",
    "        \n",
    "       \n",
    "       \n",
    "            \n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db2c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CFG:\n",
    "    \n",
    "    device = DEVICE\n",
    "    \n",
    "    THRESHOLD = 0.4\n",
    "    use_wandb = True\n",
    "    \n",
    "    ######### Dataset #########\n",
    "    \n",
    "    # stage: 'train' or 'test'\n",
    "    stage = 'train' \n",
    "    \n",
    "    # location of competition Data\n",
    "    competition_data_dir = COMPETITION_DATA_DIR_str\n",
    "    \n",
    "    # Number of slices in z-dim: 1<z_dim<65\n",
    "    z_dim = Z_DIM\n",
    "    \n",
    "    # fragments to use for training avalaible [1,2,3]\n",
    "    train_fragment_id=[2,3]\n",
    "    \n",
    "    # fragments to use for validation\n",
    "    val_fragment_id=[1]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    batch_size = 4\n",
    "    \n",
    "    # Size of the patch and stride for feeding the model\n",
    "    patch_size = PATCH_SIZE\n",
    "    stride = patch_size // 2\n",
    "    \n",
    "    \n",
    "    num_workers = 8\n",
    "    on_gpu = True\n",
    "    \n",
    "    \n",
    "    ######## Model and Lightning Model paramters ############\n",
    "    \n",
    "    # MODEL\n",
    "    model = Model_3dAtt_w_Segformer().to(DEVICE) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    checkpoint = None\n",
    "    save_directory = None\n",
    "    \n",
    "    \n",
    "    accumulate_grad_batches = 128 // batch_size  # experiments showed batch_size * accumulate_grad = 192 is optimal\n",
    "    learning_rate =  1e-5\n",
    "    eta_min = 1e-8\n",
    "    t_max = 40\n",
    "    max_epochs = 35\n",
    "    weight_decay =  1e-5\n",
    "    precision =16\n",
    "    \n",
    "    # checkpointing\n",
    "    save_top_k=5\n",
    "    \n",
    "    monitor=\"FBETA\"\n",
    "    mode=\"max\"\n",
    "    \n",
    "    \n",
    "    ####### Augemtnations ###############\n",
    "    \n",
    "    # Training Aug\n",
    "    train_transforms = [\n",
    "        # A.RandomResizedCrop(\n",
    "        #     size, size, scale=(0.85, 1.0)),\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        \n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Transpose(p=0.25),\n",
    "        A.augmentations.geometric.transforms.Affine(scale=None, \n",
    "                                                    translate_percent=(0.05, 0.2),\n",
    "                                                    translate_px=None, \n",
    "                                                    rotate=(-1, 1),\n",
    "                                                    shear=None,\n",
    "                                                    interpolation=1,\n",
    "                                                    #mask_interpolation=0,\n",
    "                                                    cval=0, \n",
    "                                                    cval_mask=0,\n",
    "                                                    p=0.25) ,\n",
    "        \n",
    "        A.augmentations.geometric.transforms.ShiftScaleRotate(shift_limit=0,\n",
    "                                                             scale_limit=(-.2, 0.1), \n",
    "                                                            rotate_limit=1.5,\n",
    "                                                           border_mode=0,\n",
    "                                                           p=0.25),\n",
    "        \n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "              A.augmentations.geometric.transforms.OpticalDistortion(distort_limit=0.1,\n",
    "                                                                  shift_limit=0.02,\n",
    "                                                                  interpolation=1,\n",
    "                                                                  border_mode=cv2.BORDER_CONSTANT,\n",
    "                                                                   value=0,\n",
    "                                                                  mask_value=0,\n",
    "                                                                  always_apply=False,\n",
    "                                                                   ),\n",
    "           \n",
    "             \n",
    "                ], p=0.4),\n",
    "        \n",
    "       \n",
    "        A.OneOf([  A.augmentations.geometric.transforms.ElasticTransform(alpha=120,\n",
    "                                                                  sigma=120*0.05,\n",
    "                                                                  alpha_affine=120 * 0.03,\n",
    "                                                                  interpolation=1,\n",
    "                                                                  border_mode=cv2.BORDER_CONSTANT,\n",
    "                                                                  value=0,\n",
    "                                                                  mask_value=0,\n",
    "                                                                  always_apply=False,\n",
    "                                                                  approximate=False,\n",
    "                                                                  same_dxdy=False,\n",
    "                                                                  #p=0.25\n",
    "                                                                        ),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.3, ),\n",
    "                 \n",
    "             ], p=0.4),\n",
    "        \n",
    "        \n",
    "       \n",
    "        A.CoarseDropout(max_holes=1, max_width=int(patch_size * 0.3), max_height=int(patch_size * 0.3), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        # A.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Validaiton Aug\n",
    "    val_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "    # Test Aug\n",
    "    test_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean=[0] * z_dim,\n",
    "            std=[1] * z_dim\n",
    "        ),\n",
    "\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cceb4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff1833c1f6f48719f8a4c928bb829e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43314217782d4592b1b5695878eed8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873df94d1fab4618afec27803b241571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#dataset = Vesuvius_Tile_Datamodule(cfg=CFG)#.to(DEVICE)\n",
    "\n",
    "\n",
    "dataset =Vesuvius_Tile_Datamodule_w_Mask(cfg=CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e68f996",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgmarus\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gregorymar577/VESUVIUS_Challenge/wandb/run-20230610_225510-oqxr8uk5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/oqxr8uk5' target=\"_blank\">clear-star-1032</a></strong> to <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge' target=\"_blank\">https://wandb.ai/gmarus/VESUVIUS_Challenge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/oqxr8uk5' target=\"_blank\">https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/oqxr8uk5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:oqxr8uk5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-star-1032</strong> at: <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/oqxr8uk5' target=\"_blank\">https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/oqxr8uk5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230610_225510-oqxr8uk5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:oqxr8uk5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e99036de71e4f0d9eaab8a8ac1f4b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669505116563718, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gregorymar577/VESUVIUS_Challenge/wandb/run-20230610_225521-031oie9j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/031oie9j' target=\"_blank\">morning-smoke-1033</a></strong> to <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge' target=\"_blank\">https://wandb.ai/gmarus/VESUVIUS_Challenge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/031oie9j' target=\"_blank\">https://wandb.ai/gmarus/VESUVIUS_Challenge/runs/031oie9j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lit_model = Lit_Model(cfg=CFG,).to(DEVICE) \n",
    "\n",
    "Checkpoint = True\n",
    "if Checkpoint:\n",
    "    lit_model = lit_model.load_from_checkpoint('logs/24_512_3dSMPmitb4/last-v14.ckpt',\n",
    "                                               #learning_rate =3e-6 ,\n",
    "                                                #t_max = 70,\n",
    "                                               #eta_min = 1e-8,\n",
    "                                               #weight_decay =  0.0001,\n",
    "                                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084c5caa",
   "metadata": {},
   "source": [
    "# Changong hyperparameters for resuming or transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc40396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos\n",
    "lit_model.loss_bce.pos_weight = torch.tensor(0.3,device='cuda')\n",
    "lit_model.loss_tversky.alpha = 0.7\n",
    "lit_model.loss_tversky.beta = 0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a68789",
   "metadata": {},
   "source": [
    "## FREEZING WEIGHTS\n",
    "\n",
    "def freeze_weights(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "        \n",
    "freeze_weights(lit_model.model.model_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3344df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bce pos tensor(0.3000, device='cuda:0')\n",
      "tver alpha 0.7\n",
      "tver beta 0.3\n"
     ]
    }
   ],
   "source": [
    "print('bce pos',lit_model.loss_bce.pos_weight)\n",
    "print('tver alpha', lit_model.loss_tversky.alpha)\n",
    "print('tver beta', lit_model.loss_tversky.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c2db2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-10 22:55:32,319 - Using 16bit None Automatic Mixed Precision (AMP)\n",
      "2023-06-10 22:55:32,338 - GPU available: True (cuda), used: True\n",
      "2023-06-10 22:55:32,339 - TPU available: False, using: 0 TPU cores\n",
      "2023-06-10 22:55:32,340 - IPU available: False, using: 0 IPUs\n",
      "2023-06-10 22:55:32,340 - HPU available: False, using: 0 HPUs\n",
      "bce pos tensor(0.3000, device='cuda:0')\n",
      "tver alpha 0.7\n",
      "tver beta 0.3\n",
      "2023-06-10 22:55:32,550 - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "2023-06-10 22:55:32,576 - \n",
      "  | Name         | Type                    | Params\n",
      "---------------------------------------------------------\n",
      "0 | metrics      | ModuleDict              | 0     \n",
      "1 | model        | Model_3dAtt_w_Segformer | 74.1 M\n",
      "2 | loss_tversky | TverskyLoss             | 0     \n",
      "3 | loss_bce     | SoftBCEWithLogitsLoss   | 0     \n",
      "---------------------------------------------------------\n",
      "74.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "74.1 M    Total params\n",
      "148.211   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregorymar577/anaconda3/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/gregorymar577/VESUVIUS_Challenge/logs/24_512_3dSMPmitb4 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1ac43c1ed549a8a48dd9627e8f896a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9846e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAVE_DIR = 'logs/24_512_3dSMPmitb4'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=5,\n",
    "    monitor=\"FBETA\",\n",
    "    mode=\"max\",\n",
    "    dirpath=SAVE_DIR,\n",
    "    filename=\"24_384_3dSMPmitb4_stage17_both_05bce30_05tver70{epoch:02d}{FBETA:.2f}{val_loss:.2f}{recall:.2f}{precision:.2f}\",\n",
    "    save_last =True,\n",
    ")\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "trainer = pl.Trainer(\n",
    "        accelerator='gpu',\n",
    "        #benchmark=True,\n",
    "        max_epochs=CFG.max_epochs,\n",
    "        check_val_every_n_epoch= 1,\n",
    "        devices=1,\n",
    "        #fast_dev_run=fast_dev_run,\n",
    "        logger=pl.loggers.CSVLogger(save_dir=SAVE_DIR),\n",
    "        log_every_n_steps=1,\n",
    "        default_root_dir = SAVE_DIR,\n",
    "        #overfit_batches=1,\n",
    "        precision= CFG.precision,\n",
    "        accumulate_grad_batches=CFG.accumulate_grad_batches, \n",
    "        callbacks=[checkpoint_callback],\n",
    "        #gradient_clip_val=1,\n",
    "        #resume_from_checkpoint ='logs/22BMasked_postTrain3d_Att3D_SmpU_mitb3_16_Bce1_05Tver50/last.ckpt'\n",
    "        #detect_anomaly=True\n",
    "        \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "print('bce pos',lit_model.loss_bce.pos_weight)\n",
    "print('tver alpha', lit_model.loss_tversky.alpha)\n",
    "print('tver beta', lit_model.loss_tversky.beta)\n",
    "\n",
    "trainer.fit(lit_model, datamodule=dataset,\n",
    "            #ckpt_path='logs/gcp_checkpoints/MoUB4_Bce015_Tver_alpha085epoch_64.ckpt'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bce pos',lit_model.loss_bce.pos_weight)\n",
    "print('tver alpha', lit_model.loss_tversky.alpha)\n",
    "print('tver beta', lit_model.loss_tversky.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trynpretraining then doing the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d161fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8840646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344a8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
