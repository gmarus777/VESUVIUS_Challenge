{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e89c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge/jupyter notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "# Make sure root project directory is named 'VESUVIUS_Challenge' for this to work\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-18:] == 'VESUVIUS_Challenge':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in the root folder of the project\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b92fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import monai\n",
    "#from monai.visualize import matshow3d\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "#import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, List\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from Data_Modules.Vesuvius_Dataset import Vesuvius_Tile_Datamodule\n",
    "from lit_models.Vesuvius_Lit_Model import Lit_Model\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lit_models.scratch_models import FPNDecoder\n",
    "from Models.PreBackbone_3D import PreBackbone_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6cde25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPN(\n",
       "  (encoder): MixVisionTransformerEncoder(\n",
       "    (patch_embed1): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed2): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed3): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed4): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (block1): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (kv): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (kv): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "        (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "    (block2): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (block3): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (kv): Linear(in_features=160, out_features=320, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (kv): Linear(in_features=160, out_features=320, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm3): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "    (block4): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.086)\n",
       "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): FPNDecoder(\n",
       "    (p5): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (p4): FPNBlock(\n",
       "      (skip_conv): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p3): FPNBlock(\n",
       "      (skip_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p2): FPNBlock(\n",
       "      (skip_conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (seg_blocks): ModuleList(\n",
       "      (0): SegmentationBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): SegmentationBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2-3): 2 x SegmentationBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (merge): MergeBlock()\n",
       "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smp.FPN(encoder_name='mit_b0', encoder_depth=5, encoder_weights='imagenet', decoder_pyramid_channels=256, decoder_segmentation_channels=128, decoder_merge_policy='cat', decoder_dropout=0.2, in_channels=3, classes=1, activation=None, upsampling=4, aux_params=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8148fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 32\n",
    "out_channels = [4,8,16,32]\n",
    "\n",
    "conv =  nn.Conv3d(in_channels=1,\n",
    "                  out_channels=4,\n",
    "                  kernel_size = (3, 1, 1),\n",
    "                  stride=(2, 1, 1),\n",
    "                  padding= (1, 0, 0)\n",
    "                  )  # (B,C,H,W) -> (B, 1 C, H, W)\n",
    "\n",
    "pool = nn.AvgPool3d(kernel_size = (2 ,1 ,1), stride=(2 ,1 ,1))\n",
    "\n",
    "global_pool =  nn.AdaptiveAvgPool3d((1, None, None))\n",
    "\n",
    "conv2 =  nn.Conv3d(in_channels=2,\n",
    "                  out_channels=8,\n",
    "                  kernel_size = (3, 1, 1),\n",
    "                  stride=(2, 1, 1),\n",
    "                  padding= (1, 0, 0)\n",
    "                  )\n",
    "\n",
    "conv3 =  nn.Conv3d(in_channels=4,\n",
    "                  out_channels=16,\n",
    "                  kernel_size = (3, 1, 1),\n",
    "                  stride=(2, 1, 1),\n",
    "                  padding= (1, 0, 0)\n",
    "                  )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e346c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dummy  = torch.randn(5,1,z_dim,256,256)\n",
    "print(dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d2f90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 16, 256, 256])\n",
      "torch.Size([5, 2, 16, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# LAYER 1\n",
    "out = conv(dummy)\n",
    "print(out.shape)\n",
    "out = out.permute(0,2,1,3,4)\n",
    "out = pool(out)\n",
    "out = out.permute(0,2,1,3,4)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03044fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 16, 256, 256])\n",
      "torch.Size([5, 1, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "out = conv(dummy)\n",
    "\n",
    "out = out.permute(0,2,1,3,4)\n",
    "out = pool(out)\n",
    "out = out.permute(0,2,1,3,4)\n",
    "\n",
    "out = conv2(out)\n",
    "out = out.permute(0,2,1,3,4)\n",
    "out = pool(out)\n",
    "out = out.permute(0,2,1,3,4)\n",
    "out = conv3(out)\n",
    "\n",
    "\n",
    "# FINAL\n",
    "out = out.permute(0,2,1,3,4)\n",
    "print(out.shape)\n",
    "out = global_pool(out)\n",
    "out = out.permute(0,2,1,3,4)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e31b7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d369261",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = torch.nn.BatchNorm3d( num_features=1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f1c73c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 4, 256, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f5da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "m_dummy = torch.randn(5,48,256,256)\n",
    "model_3d = PreBackbone_3D()\n",
    "outs = model_3d(m_dummy)\n",
    "print(outs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fb41bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(encoder_name='mit_b2',\n",
    "                 encoder_depth=5,\n",
    "                 encoder_weights='imagenet', \n",
    "                 decoder_use_batchnorm=True, \n",
    "                 decoder_channels=(512, 256, 128, 64, 32,),\n",
    "                 decoder_attention_type=None,\n",
    "                 in_channels=3,\n",
    "                 classes=1, activation=None, aux_params=None)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62685647",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_outs = model(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d76af6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 256, 256])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8cbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
