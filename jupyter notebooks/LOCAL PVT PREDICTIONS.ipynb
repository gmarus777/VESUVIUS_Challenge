{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5d9a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge/jupyter notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "# Make sure root project directory is named 'VESUVIUS_Challenge' for this to work\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-18:] == 'VESUVIUS_Challenge':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in the root folder of the project\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac817c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-23 15:45:29,620 - Created a temporary directory at /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp7yo077vf\n",
      "2023-05-23 15:45:29,621 - Writing /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp7yo077vf/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, List\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from Data_Modules.Vesuvius_Dataset import Vesuvius_Tile_Datamodule\n",
    "from lit_models.Vesuvius_Lit_Model import Lit_Model\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from lit_models.scratch_models import FPNDecoder\n",
    "import gc\n",
    "from Models.PreBackbone_3d_Zdim import PreBackbone_3D_ZDIM\n",
    "from Models.PreBackbone_3D import PreBackbone_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e38745",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = 'logs/gcp_checkpoints/3dAttn_w_Swin_24_05bce1_05tver50epoch_9.ckpt'\n",
    "SAMPLE_SUBMISSION = 'kaggle/input/vesuvius-challenge-ink-detection/sample_submission.csv'\n",
    "\n",
    "\n",
    "PATCH_SIZE = 256\n",
    "Z_DIM = 24\n",
    "COMPETITION_DATA_DIR_str =  \"kaggle/input/vesuvius-challenge-ink-detection/\"\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "# change to the line below if not using Apple's M1 or chips\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f1b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_3dAtt_w_Segformer(nn.Module):\n",
    "    def __init__(self ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_3d = PreBackbone_3D_ZDIM(z_dim=Z_DIM, out_channels = 4).to(DEVICE) \n",
    "        \n",
    "       \n",
    "        self.model_2d = monai.networks.nets.SwinUNETR(img_size = 256,\n",
    "                                                      in_channels = 4 ,\n",
    "                                                      out_channels = 1 ,\n",
    "                                                      depths=(2, 2, 2, 2,2),\n",
    "                                                      num_heads=(3, 6, 12, 24,48),\n",
    "                                                      feature_size=48,\n",
    "                                                      norm_name='instance',\n",
    "                                                      drop_rate=0.0,\n",
    "                                                      attn_drop_rate=0.1,\n",
    "                                                      dropout_path_rate=0.0,\n",
    "                                                      normalize=True,\n",
    "                                                      use_checkpoint=False,\n",
    "                                                      spatial_dims=2,\n",
    "                                                      downsample='mergingv2').to(DEVICE) \n",
    "      \n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        outs_3d = self.model_3d(x)\n",
    "        logits = self.model_2d(outs_3d)\n",
    "        \n",
    "       \n",
    "       \n",
    "            \n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d89aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CFG:\n",
    "    \n",
    "    device = DEVICE\n",
    "    \n",
    "    THRESHOLD = 0.5\n",
    "    use_wandb = False\n",
    "    \n",
    "    ######### Dataset #########\n",
    "    \n",
    "    # stage: 'train' or 'test'\n",
    "    stage = 'test' \n",
    "    \n",
    "    # location of competition Data\n",
    "    competition_data_dir = COMPETITION_DATA_DIR_str\n",
    "    \n",
    "    # Number of slices in z-dim: 1<z_dim<65\n",
    "    z_dim = Z_DIM\n",
    "    \n",
    "    # fragments to use for training avalaible [1,2,3]\n",
    "    train_fragment_id=[2,3]\n",
    "    \n",
    "    # fragments to use for validation\n",
    "    val_fragment_id=[1]\n",
    "    \n",
    "    test_fragment_ids = ['a','b']\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    batch_size = 4\n",
    "    \n",
    "    # Size of the patch and stride for feeding the model\n",
    "    patch_size = PATCH_SIZE\n",
    "    stride = patch_size // 2\n",
    "    \n",
    "    \n",
    "    num_workers = 0\n",
    "    on_gpu = True\n",
    "    \n",
    "    \n",
    "    ######## Model and Lightning Model paramters ############\n",
    "    \n",
    "    # MODEL\n",
    "    model = Model_3dAtt_w_Segformer().to(DEVICE) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    checkpoint = None\n",
    "    save_directory = None\n",
    "    \n",
    "    \n",
    "    accumulate_grad_batches = 192// batch_size  # experiments showed batch_size * accumulate_grad = 192 is optimal\n",
    "    learning_rate = 0.0001\n",
    "    eta_min = 1e-7\n",
    "    t_max = 80\n",
    "    max_epochs = 120\n",
    "    weight_decay =  0.0001\n",
    "    precision =16\n",
    "    \n",
    "    # checkpointing\n",
    "    save_top_k=5\n",
    "    \n",
    "    monitor=\"FBETA\"\n",
    "    mode=\"max\"\n",
    "    \n",
    "    \n",
    "    ####### Augemtnations ###############\n",
    "    \n",
    "    # Training Aug\n",
    "    train_transforms = [\n",
    "        # A.RandomResizedCrop(\n",
    "        #     size, size, scale=(0.85, 1.0)),\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.CoarseDropout(max_holes=1, max_width=int(patch_size * 0.3), max_height=int(patch_size * 0.3), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        # A.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Validaiton Aug\n",
    "    val_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "    # Test Aug\n",
    "    test_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean=[0] * z_dim,\n",
    "            std=[1] * z_dim\n",
    "        ),\n",
    "\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628f7f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lit_Model(\n",
       "  (metrics): ModuleDict(\n",
       "    (train_metrics): MetricCollection(\n",
       "      (dice): Dice(),\n",
       "      prefix=train_\n",
       "    )\n",
       "    (val_metrics): MetricCollection(\n",
       "      (dice): Dice(),\n",
       "      prefix=val_\n",
       "    )\n",
       "  )\n",
       "  (model): Model_3dAtt_w_Segformer(\n",
       "    (model_3d): PreBackbone_3D_ZDIM(\n",
       "      (embed_layer): Embed(\n",
       "        (conv_3d): Conv3d(1, 4, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0))\n",
       "        (conv_3d_embed): Conv3d(4, 1, kernel_size=(1, 4, 4), stride=(1, 4, 4), padding=(0, 1, 1))\n",
       "        (norm): LayerNorm2d((4,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_embed): LayerNorm2d((1,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (attention): EfficientMultiHeadAttention(\n",
       "        (reducer): Sequential(\n",
       "          (0): Conv2d(12, 12, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (1): LayerNorm_att((12,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (att): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (pool): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)\n",
       "      (global_pool): AdaptiveAvgPool3d(output_size=(1, None, None))\n",
       "      (global_pool_final): AdaptiveAvgPool3d(output_size=(4, None, None))\n",
       "      (batch_norm): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
       "      (conv1): Conv3d(5, 8, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
       "      (conv2): Conv3d(4, 16, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
       "      (conv3): Conv3d(8, 32, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
       "      (conv4): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "    (model_2d): SwinUNETR(\n",
       "      (swinViT): SwinTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(4, 48, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (layers1): ModuleList(\n",
       "          (0): BasicLayer(\n",
       "            (blocks): ModuleList(\n",
       "              (0-1): 2 x SwinTransformerBlock(\n",
       "                (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "                  (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "                (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): MLPBlock(\n",
       "                  (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
       "                  (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
       "                  (fn): GELU(approximate='none')\n",
       "                  (drop1): Dropout(p=0.0, inplace=False)\n",
       "                  (drop2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMergingV2(\n",
       "              (reduction): Linear(in_features=192, out_features=96, bias=False)\n",
       "              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers2): ModuleList(\n",
       "          (0): BasicLayer(\n",
       "            (blocks): ModuleList(\n",
       "              (0-1): 2 x SwinTransformerBlock(\n",
       "                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "                  (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): MLPBlock(\n",
       "                  (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
       "                  (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
       "                  (fn): GELU(approximate='none')\n",
       "                  (drop1): Dropout(p=0.0, inplace=False)\n",
       "                  (drop2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMergingV2(\n",
       "              (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers3): ModuleList(\n",
       "          (0): BasicLayer(\n",
       "            (blocks): ModuleList(\n",
       "              (0-1): 2 x SwinTransformerBlock(\n",
       "                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "                  (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): MLPBlock(\n",
       "                  (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
       "                  (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                  (fn): GELU(approximate='none')\n",
       "                  (drop1): Dropout(p=0.0, inplace=False)\n",
       "                  (drop2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMergingV2(\n",
       "              (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers4): ModuleList(\n",
       "          (0): BasicLayer(\n",
       "            (blocks): ModuleList(\n",
       "              (0-1): 2 x SwinTransformerBlock(\n",
       "                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "                  (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): MLPBlock(\n",
       "                  (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                  (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                  (fn): GELU(approximate='none')\n",
       "                  (drop1): Dropout(p=0.0, inplace=False)\n",
       "                  (drop2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): PatchMergingV2(\n",
       "              (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (encoder1): UnetrBasicBlock(\n",
       "        (layer): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(4, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv3): Convolution(\n",
       "            (conv): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (norm3): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder2): UnetrBasicBlock(\n",
       "        (layer): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder3): UnetrBasicBlock(\n",
       "        (layer): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder4): UnetrBasicBlock(\n",
       "        (layer): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder10): UnetrBasicBlock(\n",
       "        (layer): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (decoder5): UnetrUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv3): Convolution(\n",
       "            (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (norm3): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (decoder4): UnetrUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv3): Convolution(\n",
       "            (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (norm3): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (decoder3): UnetrUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv3): Convolution(\n",
       "            (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (decoder2): UnetrUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose2d(96, 48, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv3): Convolution(\n",
       "            (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (norm3): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (decoder1): UnetrUpBlock(\n",
       "        (transp_conv): Convolution(\n",
       "          (conv): ConvTranspose2d(48, 48, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        )\n",
       "        (conv_block): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv3): Convolution(\n",
       "            (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (norm3): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (out): UnetOutBlock(\n",
       "        (conv): Convolution(\n",
       "          (conv): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_tversky): TverskyLoss()\n",
       "  (loss_bce): SoftBCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_model = Lit_Model(cfg=CFG)\n",
    "\n",
    "lit_model = lit_model.load_from_checkpoint(CHECKPOINT, cfg=CFG,).to(CFG.device)\n",
    "\n",
    "lit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0095b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_dataset(fragment_id):\n",
    "    test_images = read_image(fragment_id)\n",
    "    \n",
    "    x1_list = list(range(0, test_images.shape[1]-CFG.patch_size+1, CFG.stride))\n",
    "    y1_list = list(range(0, test_images.shape[0]-CFG.patch_size+1, CFG.stride))\n",
    "    \n",
    "    test_images_list = []\n",
    "    xyxys = []\n",
    "    for y1 in y1_list:\n",
    "        for x1 in x1_list:\n",
    "            y2 = y1 + CFG.patch_size\n",
    "            x2 = x1 + CFG.patch_size\n",
    "            \n",
    "            test_images_list.append(test_images[y1:y2, x1:x2])\n",
    "            xyxys.append((x1, y1, x2, y2))\n",
    "    xyxys = np.stack(xyxys)\n",
    "            \n",
    "    test_dataset = CustomDataset(test_images_list, CFG, transform=get_transforms(data='valid', cfg=CFG))\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=CFG.batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=CFG.num_workers, pin_memory=CFG.on_gpu, drop_last=False)\n",
    "    \n",
    "    return test_loader, xyxys\n",
    "\n",
    "\n",
    "def get_transforms(data, cfg):\n",
    "    return A.Compose(\n",
    "        [\n",
    "        A.Resize(CFG.patch_size, CFG.patch_size),\n",
    "        A.Normalize(\n",
    "            mean=[0] * CFG.z_dim,\n",
    "            std=[1] * CFG.z_dim\n",
    "        ),\n",
    "\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "def read_image(fragment_id):\n",
    "    images = []\n",
    "\n",
    "    # idxs = range(65)\n",
    "    mid = 65 // 2\n",
    "    start = mid - CFG.z_dim // 2\n",
    "    end = mid + CFG.z_dim // 2\n",
    "    idxs = range(start, end)\n",
    "\n",
    "    for i in tqdm(idxs):\n",
    "        \n",
    "        image = cv2.imread(COMPETITION_DATA_DIR_str + f\"test/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n",
    "\n",
    "        pad0 = (CFG.patch_size - image.shape[0] % CFG.patch_size)\n",
    "        pad1 = (CFG.patch_size - image.shape[1] % CFG.patch_size)\n",
    "\n",
    "        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "        images.append(image)\n",
    "    images = np.stack(images, axis=2)\n",
    "    \n",
    "    return images\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, cfg, labels=None, transform=None):\n",
    "        self.images = images\n",
    "        self.cfg = cfg\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.xyxys)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # x1, y1, x2, y2 = self.xyxys[idx]\n",
    "        image = self.images[idx]\n",
    "        data = self.transform(image=image)\n",
    "        image = data['image']\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    \n",
    "def rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    # pixels = (pixels >= thr).astype(int)\n",
    "    \n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79855a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f94cf916b14f83b403aa6d507e8a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ce7066ac044dbf800dd4071ea3194f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Conv3D is not supported on MPS",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 30\u001b[0m     y_preds \u001b[38;5;241m=\u001b[39m \u001b[43mlit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     y_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(y_preds)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m#y_preds = y_preds.numpy()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#print(type(y_preds))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PROJECT_ML/VESUVIUS_Challenge/lit_models/Vesuvius_Lit_Model.py:154\u001b[0m, in \u001b[0;36mLit_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mModel_3dAtt_w_Segformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 28\u001b[0m     outs_3d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_2d(outs_3d)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PROJECT_ML/VESUVIUS_Challenge/Models/PreBackbone_3d_Zdim.py:82\u001b[0m, in \u001b[0;36mPreBackbone_3D_ZDIM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Stage 1 Embedding and Z_Dim attention\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# embed layer produces tensors:\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# x_orig = (B, emdedding_dims[0], C/2, H, W) for residual connection\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# x_att = (B, 1, C/2, H/4, W/4)\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m x_orig, x_att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m x_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(x_orig)\n\u001b[1;32m     84\u001b[0m x_att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(x_att)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PROJECT_ML/VESUVIUS_Challenge/Models/PreBackbone_3d_Zdim.py:159\u001b[0m, in \u001b[0;36mEmbed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 159\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m    161\u001b[0m     x_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_3d_embed(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Conv3D is not supported on MPS"
     ]
    }
   ],
   "source": [
    "#224 stride=8\n",
    "THRESHOLD =0.2\n",
    "results = []\n",
    "outputs = []\n",
    "for fragment_id in CFG.test_fragment_ids:\n",
    "    \n",
    "    test_loader, xyxys = make_test_dataset(fragment_id)\n",
    "    \n",
    "    binary_mask = cv2.imread(COMPETITION_DATA_DIR_str + f\"test/{fragment_id}/mask.png\", 0)\n",
    "    binary_mask = (binary_mask / 255).astype(int)\n",
    "    binary_mask = torch.tensor(binary_mask)#.to(DEVICE)\n",
    "    \n",
    "    ori_h = binary_mask.shape[0]\n",
    "    ori_w = binary_mask.shape[1]\n",
    "    # mask = mask / 255\n",
    "\n",
    "    pad0 = (CFG.patch_size - binary_mask.shape[0] % CFG.patch_size)\n",
    "    pad1 = (CFG.patch_size - binary_mask.shape[1] % CFG.patch_size)\n",
    "\n",
    "    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "    \n",
    "    mask_pred = torch.zeros(binary_mask.shape).to(CFG.device)\n",
    "    mask_count = torch.zeros(binary_mask.shape).to(CFG.device)\n",
    "\n",
    "    for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        images = images.to(DEVICE)\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_preds = lit_model(images)\n",
    "            y_preds = torch.sigmoid(y_preds)\n",
    "            #y_preds = y_preds.numpy()\n",
    "            #print(type(y_preds))\n",
    "\n",
    "        start_idx = step*CFG.batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        #xyxys = torch.from_numpy(xyxys)\n",
    "        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n",
    "            mask_count[y1:y2, x1:x2] += torch.ones((CFG.patch_size, CFG.patch_size)).to(DEVICE)\n",
    "    \n",
    "    plt.imshow(mask_count.to('cpu'))\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'mask_count_min: {mask_count.min()}')\n",
    "    mask_pred /= mask_count\n",
    "    \n",
    "    mask_pred = mask_pred[:ori_h, :ori_w]\n",
    "    binary_mask = binary_mask[:ori_h, :ori_w]\n",
    "    \n",
    "    mask_pred = mask_pred.to('cpu').numpy()\n",
    "    outputs.append(mask_pred)\n",
    "    mask_pred = (mask_pred >= THRESHOLD).astype(int)\n",
    "    mask_pred *= binary_mask\n",
    "    \n",
    "    plt.imshow(mask_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    inklabels_rle = rle(mask_pred)\n",
    "    \n",
    "    \n",
    "    results.append( inklabels_rle)\n",
    "    \n",
    "\n",
    "    del mask_pred, mask_count\n",
    "    del test_loader\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.12\n",
    "for image in outputs:\n",
    "    mask_pred = image \n",
    "    mask_pred = (mask_pred >= THRESHOLD).astype(int)\n",
    "    plt.imshow(mask_pred)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a418196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
