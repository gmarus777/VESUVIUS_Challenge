{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71200594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we take care of paths.\n",
    "# Make sure root project directory is named 'VESUVIUS_Challenge' for this to work\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-18:] == 'VESUVIUS_Challenge':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in the root folder of the project\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f6cdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-19 14:38:39,487 - Created a temporary directory at /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp2nbyyvtj\n",
      "2023-05-19 14:38:39,488 - Writing /var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/tmp2nbyyvtj/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, List\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from Data_Modules.Vesuvius_Dataset import Vesuvius_Tile_Datamodule\n",
    "from lit_models.Vesuvius_Lit_Model import Lit_Model\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn\n",
    "from Models.PVT2 import PyramidVisionTransformerV2\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from lit_models.scratch_models import FPNDecoder\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9a9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = 'logs/gcp_checkpoints/PVT_FPN_bce50epoch_6.ckpt'\n",
    "SAMPLE_SUBMISSION = 'kaggle/input/vesuvius-challenge-ink-detection/sample_submission.csv'\n",
    "\n",
    "\n",
    "PATCH_SIZE = 256\n",
    "Z_DIM = 16\n",
    "COMPETITION_DATA_DIR_str =  \"kaggle/input/vesuvius-challenge-ink-detection/\"\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "# change to the line below if not using Apple's M1 or chips\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3899fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PVT_w_FPN(nn.Module):\n",
    "    def __init__(self, in_channels = Z_DIM,  embed_dims=[ 64, 128, 256, 512], n_classes=1, ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dims = embed_dims\n",
    "        \n",
    "       \n",
    "        self.pvt = PyramidVisionTransformerV2(img_size = PATCH_SIZE,\n",
    "                                  patch_size = 4,\n",
    "                                  in_chans = Z_DIM,\n",
    "                                  num_classes = 1,\n",
    "                                  embed_dims = embed_dims,\n",
    "                                num_heads=[1, 2, 4, 8],\n",
    "                                  mlp_ratios=[8, 8, 4, 4],\n",
    "                                  qkv_bias=True,\n",
    "                                  qk_scale=None,\n",
    "                                  drop_rate=0.,\n",
    "                                attn_drop_rate=0.,\n",
    "                                  drop_path_rate=0.1,\n",
    "                                  norm_layer=partial(nn.LayerNorm, eps=1e-3),\n",
    "                                #norm_layer=nn.LayerNorm,          \n",
    "                                  depths=[2, 2, 2,2],\n",
    "                                  sr_ratios=[4, 4, 2, 1]\n",
    "                                 ).to(DEVICE) \n",
    "        \n",
    "        self.FPN = FPNDecoder(\n",
    "                            in_channels = Z_DIM,\n",
    "                            encoder_channels = embed_dims ,\n",
    "                            encoder_depth=5,\n",
    "                            pyramid_channels=256,\n",
    "                            segmentation_channels=128,\n",
    "                            dropout=0.,\n",
    "                            merge_policy=\"cat\",).to(DEVICE) \n",
    "        \n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(1)\n",
    "        #x = self.pre_model3d(x)\n",
    "        #x = x.squeeze(1)\n",
    "        \n",
    "        pvt_outs = self.pvt(x)\n",
    "        \n",
    "        logits = self.FPN(*pvt_outs)\n",
    "        \n",
    "       \n",
    "       \n",
    "            \n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbf0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CFG:\n",
    "    \n",
    "    device = DEVICE\n",
    "    \n",
    "    THRESHOLD = 0.5\n",
    "    use_wandb = False\n",
    "    \n",
    "    ######### Dataset #########\n",
    "    \n",
    "    # stage: 'train' or 'test'\n",
    "    stage = 'test' \n",
    "    \n",
    "    # location of competition Data\n",
    "    competition_data_dir = COMPETITION_DATA_DIR_str\n",
    "    \n",
    "    # Number of slices in z-dim: 1<z_dim<65\n",
    "    z_dim = Z_DIM\n",
    "    \n",
    "    # fragments to use for training avalaible [1,2,3]\n",
    "    train_fragment_id=[2,3]\n",
    "    \n",
    "    # fragments to use for validation\n",
    "    val_fragment_id=[1]\n",
    "    \n",
    "    test_fragment_ids = ['a','b']\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    batch_size = 4\n",
    "    \n",
    "    # Size of the patch and stride for feeding the model\n",
    "    patch_size = PATCH_SIZE\n",
    "    stride = patch_size // 8\n",
    "    \n",
    "    \n",
    "    num_workers = 0\n",
    "    on_gpu = True\n",
    "    \n",
    "    \n",
    "    ######## Model and Lightning Model paramters ############\n",
    "    \n",
    "    # MODEL\n",
    "    model = PVT_w_FPN(in_channels = z_dim,  embed_dims=[  64, 128, 256, 512]).to(DEVICE) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    checkpoint = None\n",
    "    save_directory = None\n",
    "    \n",
    "    \n",
    "    accumulate_grad_batches = 192// batch_size  # experiments showed batch_size * accumulate_grad = 192 is optimal\n",
    "    learning_rate = 0.0001\n",
    "    eta_min = 1e-7\n",
    "    t_max = 80\n",
    "    max_epochs = 120\n",
    "    weight_decay =  0.0001\n",
    "    precision =16\n",
    "    \n",
    "    # checkpointing\n",
    "    save_top_k=5\n",
    "    \n",
    "    monitor=\"FBETA\"\n",
    "    mode=\"max\"\n",
    "    \n",
    "    \n",
    "    ####### Augemtnations ###############\n",
    "    \n",
    "    # Training Aug\n",
    "    train_transforms = [\n",
    "        # A.RandomResizedCrop(\n",
    "        #     size, size, scale=(0.85, 1.0)),\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.CoarseDropout(max_holes=1, max_width=int(patch_size * 0.3), max_height=int(patch_size * 0.3), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        # A.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Validaiton Aug\n",
    "    val_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean= [0] * z_dim,\n",
    "            std= [1] * z_dim\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "    # Test Aug\n",
    "    test_transforms = [\n",
    "        A.Resize(patch_size, patch_size),\n",
    "        A.Normalize(\n",
    "            mean=[0] * z_dim,\n",
    "            std=[1] * z_dim\n",
    "        ),\n",
    "\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42433c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lit_Model(\n",
       "  (metrics): ModuleDict(\n",
       "    (train_metrics): MetricCollection(\n",
       "      (dice): Dice(),\n",
       "      prefix=train_\n",
       "    )\n",
       "    (val_metrics): MetricCollection(\n",
       "      (dice): Dice(),\n",
       "      prefix=val_\n",
       "    )\n",
       "  )\n",
       "  (model): PVT_w_FPN(\n",
       "    (pvt): PyramidVisionTransformerV2(\n",
       "      (patch_embed1): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(16, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "        (norm): LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "      )\n",
       "      (block1): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=64, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.014)\n",
       "          (norm2): LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=64, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "      (patch_embed2): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((128,), eps=0.001, elementwise_affine=True)\n",
       "      )\n",
       "      (block2): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((128,), eps=0.001, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=0.001, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.029)\n",
       "          (norm2): LayerNorm((128,), eps=0.001, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((128,), eps=0.001, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=0.001, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.043)\n",
       "          (norm2): LayerNorm((128,), eps=0.001, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm2): LayerNorm((128,), eps=0.001, elementwise_affine=True)\n",
       "      (patch_embed3): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((256,), eps=0.001, elementwise_affine=True)\n",
       "      )\n",
       "      (block3): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((256,), eps=0.001, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((256,), eps=0.001, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.057)\n",
       "          (norm2): LayerNorm((256,), eps=0.001, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((256,), eps=0.001, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((256,), eps=0.001, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.071)\n",
       "          (norm2): LayerNorm((256,), eps=0.001, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm3): LayerNorm((256,), eps=0.001, elementwise_affine=True)\n",
       "      (patch_embed4): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "      )\n",
       "      (block4): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.086)\n",
       "          (norm2): LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm4): LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "    )\n",
       "    (FPN): FPNDecoder(\n",
       "      (p5): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p4): FPNBlock(\n",
       "        (skip_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (p3): FPNBlock(\n",
       "        (skip_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (p2): FPNBlock(\n",
       "        (skip_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (p1): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (seg_blocks): ModuleList(\n",
       "        (0): SegmentationBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (4): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SegmentationBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SegmentationBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SegmentationBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv3x3GNReLU(\n",
       "              (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "              (block): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (merge): MergeBlock()\n",
       "      (dropout): Dropout2d(p=0.0, inplace=True)\n",
       "      (block): Conv3x3GNReLU(\n",
       "        (downsample_4x): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_fuse): Sequential(\n",
       "        (0): ConvTranspose2d(640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): SyncBatchNorm(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): ConvTranspose2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (linear_pred): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (dice_bce): DiceBCELoss(\n",
       "    (bce): BCEWithLogitsLoss()\n",
       "  )\n",
       "  (loss_tversky): TverskyLoss()\n",
       "  (loss_bce): SoftBCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_model = Lit_Model(cfg=CFG)\n",
    "\n",
    "lit_model = lit_model.load_from_checkpoint(CHECKPOINT, cfg=CFG,).to(CFG.device)\n",
    "\n",
    "lit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66dadd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_dataset(fragment_id):\n",
    "    test_images = read_image(fragment_id)\n",
    "    \n",
    "    x1_list = list(range(0, test_images.shape[1]-CFG.patch_size+1, CFG.stride))\n",
    "    y1_list = list(range(0, test_images.shape[0]-CFG.patch_size+1, CFG.stride))\n",
    "    \n",
    "    test_images_list = []\n",
    "    xyxys = []\n",
    "    for y1 in y1_list:\n",
    "        for x1 in x1_list:\n",
    "            y2 = y1 + CFG.patch_size\n",
    "            x2 = x1 + CFG.patch_size\n",
    "            \n",
    "            test_images_list.append(test_images[y1:y2, x1:x2])\n",
    "            xyxys.append((x1, y1, x2, y2))\n",
    "    xyxys = np.stack(xyxys)\n",
    "            \n",
    "    test_dataset = CustomDataset(test_images_list, CFG, transform=get_transforms(data='valid', cfg=CFG))\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=CFG.batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=CFG.num_workers, pin_memory=CFG.on_gpu, drop_last=False)\n",
    "    \n",
    "    return test_loader, xyxys\n",
    "\n",
    "\n",
    "def get_transforms(data, cfg):\n",
    "    return A.Compose(\n",
    "        [\n",
    "        A.Resize(CFG.patch_size, CFG.patch_size),\n",
    "        A.Normalize(\n",
    "            mean=[0] * CFG.z_dim,\n",
    "            std=[1] * CFG.z_dim\n",
    "        ),\n",
    "\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "def read_image(fragment_id):\n",
    "    images = []\n",
    "\n",
    "    # idxs = range(65)\n",
    "    mid = 65 // 2\n",
    "    start = mid - CFG.z_dim // 2\n",
    "    end = mid + CFG.z_dim // 2\n",
    "    idxs = range(start, end)\n",
    "\n",
    "    for i in tqdm(idxs):\n",
    "        \n",
    "        image = cv2.imread(COMPETITION_DATA_DIR_str + f\"test/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n",
    "\n",
    "        pad0 = (CFG.patch_size - image.shape[0] % CFG.patch_size)\n",
    "        pad1 = (CFG.patch_size - image.shape[1] % CFG.patch_size)\n",
    "\n",
    "        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "        images.append(image)\n",
    "    images = np.stack(images, axis=2)\n",
    "    \n",
    "    return images\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, cfg, labels=None, transform=None):\n",
    "        self.images = images\n",
    "        self.cfg = cfg\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.xyxys)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # x1, y1, x2, y2 = self.xyxys[idx]\n",
    "        image = self.images[idx]\n",
    "        data = self.transform(image=image)\n",
    "        image = data['image']\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    \n",
    "def rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    # pixels = (pixels >= thr).astype(int)\n",
    "    \n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5670aa077bf400c8beaead4f86f9a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0fa61d23bc40e79ff2ad4fb765678a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#224 stride=8\n",
    "THRESHOLD =0.2\n",
    "results = []\n",
    "outputs = []\n",
    "for fragment_id in CFG.test_fragment_ids:\n",
    "    \n",
    "    test_loader, xyxys = make_test_dataset(fragment_id)\n",
    "    \n",
    "    binary_mask = cv2.imread(COMPETITION_DATA_DIR_str + f\"test/{fragment_id}/mask.png\", 0)\n",
    "    binary_mask = (binary_mask / 255).astype(int)\n",
    "    binary_mask = torch.tensor(binary_mask)#.to(DEVICE)\n",
    "    \n",
    "    ori_h = binary_mask.shape[0]\n",
    "    ori_w = binary_mask.shape[1]\n",
    "    # mask = mask / 255\n",
    "\n",
    "    pad0 = (CFG.patch_size - binary_mask.shape[0] % CFG.patch_size)\n",
    "    pad1 = (CFG.patch_size - binary_mask.shape[1] % CFG.patch_size)\n",
    "\n",
    "    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "    \n",
    "    mask_pred = torch.zeros(binary_mask.shape).to(CFG.device)\n",
    "    mask_count = torch.zeros(binary_mask.shape).to(CFG.device)\n",
    "\n",
    "    for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        images = images.to(DEVICE)\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_preds = lit_model(images)\n",
    "            y_preds = torch.sigmoid(y_preds)\n",
    "            #y_preds = y_preds.numpy()\n",
    "            #print(type(y_preds))\n",
    "\n",
    "        start_idx = step*CFG.batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        #xyxys = torch.from_numpy(xyxys)\n",
    "        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n",
    "            mask_count[y1:y2, x1:x2] += torch.ones((CFG.patch_size, CFG.patch_size)).to(DEVICE)\n",
    "    \n",
    "    plt.imshow(mask_count.to('cpu'))\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'mask_count_min: {mask_count.min()}')\n",
    "    mask_pred /= mask_count\n",
    "    \n",
    "    mask_pred = mask_pred[:ori_h, :ori_w]\n",
    "    binary_mask = binary_mask[:ori_h, :ori_w]\n",
    "    \n",
    "    mask_pred = mask_pred.to('cpu').numpy()\n",
    "    outputs.append(mask_pred)\n",
    "    mask_pred = (mask_pred >= THRESHOLD).astype(int)\n",
    "    mask_pred *= binary_mask\n",
    "    \n",
    "    plt.imshow(mask_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    inklabels_rle = rle(mask_pred)\n",
    "    \n",
    "    \n",
    "    results.append( inklabels_rle)\n",
    "    \n",
    "\n",
    "    del mask_pred, mask_count\n",
    "    del test_loader\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.13\n",
    "for image in outputs:\n",
    "    mask_pred = image \n",
    "    mask_pred = (mask_pred >= THRESHOLD).astype(int)\n",
    "    plt.imshow(mask_pred)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097322e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
