{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfdc84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge/jupyter notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/VESUVIUS_Challenge\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-18:] == 'VESUVIUS_Challenge':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5636399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import monai\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from Data_Modules.Vesuvius_Tile_Dataset import Vesuvius_Tile_Datamodule\n",
    "import matplotlib.patches as patches\n",
    "from lit_models.UNET_TILE import UNET_TILE_lit\n",
    "from monai.visualize import matshow3d\n",
    "import einops\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd419f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 224\n",
    "Z_DIM = 8\n",
    "\n",
    "class CFG:\n",
    "    \n",
    "    train_fragment_id=[2,3]\n",
    "    val_fragment_id=[1]\n",
    "    batch_size = 32\n",
    "    patch_size = PATCH_SIZE\n",
    "    z_dim = Z_DIM\n",
    "    stride = patch_size // 2\n",
    "    #comp_dataset_path = COMPETITION_DATA_DIR\n",
    "    num_workers = 0\n",
    "    on_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554acfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Vesuvius_Tile_Datamodule(cfg=CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf03728",
   "metadata": {},
   "source": [
    "dataloader = iter(dataset.train_dataloader())\n",
    "for i in range(1):\n",
    "    # Get image and label from train data -- change number for different ones\n",
    "    subvolumes, inklabels = next(dataloader)\n",
    "    print('subvolume shape:',subvolumes.shape)\n",
    "    print('inklabel shape:',inklabels.shape)\n",
    "    for subvolume,  inklabel in zip(subvolumes, inklabels):\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "                for idx, image in enumerate((subvolume,  inklabel)):\n",
    "                    if idx==0:\n",
    "                        axes[idx].imshow(image[0])\n",
    "                    else:\n",
    "                         axes[idx].imshow(image.squeeze(0))\n",
    "\n",
    "                plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb8d6d",
   "metadata": {},
   "source": [
    "plot_dataset = dataset.train_dataloader()\n",
    "plot_count = 0\n",
    "for i in range(1000):\n",
    "    image, mask = plot_dataset[i]\n",
    "    #data = transform(image=image, mask=mask)\n",
    "    aug_image = image#.squeeze(0) # data['image']\n",
    "    aug_mask = mask#.squeeze(0) #data['mask']\n",
    "    print(image.shape, mask.shape)\n",
    "\n",
    "    if mask.sum() == 0:\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 8))\n",
    "    axes[0].imshow(image[..., 0], cmap=\"gray\")\n",
    "    axes[1].imshow(mask, cmap=\"gray\")\n",
    "    #axes[2].imshow(aug_image[..., 0], cmap=\"gray\")\n",
    "    #axes[3].imshow(aug_mask, cmap=\"gray\")\n",
    "    \n",
    "    #plt.savefig(CFG.figures_dir + f'aug_fold_{CFG.valid_id}_{plot_count}.png')\n",
    "\n",
    "    plot_count += 1\n",
    "    if plot_count == 5:\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = UNET_TILE_lit(\n",
    "        use_wandb = True,\n",
    "        z_dim = Z_DIM,\n",
    "        patch_size = (PATCH_SIZE,PATCH_SIZE),\n",
    "        sw_batch_size=8 ,\n",
    "        eta_min = 1e-8,\n",
    "        t_max = 120,\n",
    "        max_epochs = 300,\n",
    "        weight_decay =  0.0001,\n",
    "        learning_rate = 0.00001,\n",
    "        gamma = 0.85,)\n",
    "\n",
    "\n",
    "FROM_CHECKPOINT = F\n",
    "if FROM_CHECKPOINT:\n",
    "    lit_model = lit_model.load_from_checkpoint('logs/Local_Originalgood_1/last-v1.ckpt', \n",
    "                                              #patch_size = (512,512),\n",
    "                                              #learning_rate = 0.0001,\n",
    "                                               #weight_decay =  .001,\n",
    "                                               #eta_min = 1e-7,\n",
    "                                               #max_epochs = 100,\n",
    "                                             #sw_batch_size = 8\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac7bd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=5,\n",
    "    monitor=\"fbeta_4\",\n",
    "    mode=\"max\",\n",
    "    dirpath=\"logs/BCE2+05Tversky_Local_Originalgood\",\n",
    "    filename=\"BCE2+05Tversky_Local_Originalgood{epoch:02d}{val_loss:.2f}{fbeta_4:.2f}{recall:.2f}{precision:.2f}\",\n",
    "    save_last =True,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        accelerator='mps',\n",
    "        #benchmark=True,\n",
    "        max_epochs=120,\n",
    "        check_val_every_n_epoch= 1,\n",
    "        devices=1,\n",
    "        #fast_dev_run=fast_dev_run,\n",
    "        logger=pl.loggers.CSVLogger(save_dir='logs/BCE2+05Tversky_Local_Originalgood/'),\n",
    "        log_every_n_steps=1,\n",
    "        default_root_dir = 'logs/BCE2+05Tversky_Local_Originalgood/',\n",
    "        #overfit_batches=1,\n",
    "        #precision=16,\n",
    "        accumulate_grad_batches=1, \n",
    "        callbacks=[checkpoint_callback],\n",
    "        #resume_from_checkpoint ='logs/smp_unet_32_.5/lightning_logs/version_3/checkpoints/FocalDice_768epoch=123FBETA=0.30recall=0.77precision=0.26.ckpt'\n",
    "        \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer.fit(lit_model, datamodule=dataset,\n",
    "            #ckpt_path='logs/Local_SMPEffB3_Tile_12_224patch/last.ckpt'\n",
    "           )\n",
    "# resume_from_checkpoint = \n",
    "#ckpt_path='logs/unet_smp-epoch=102-val_loss=0.00.ckpt'\n",
    "# ckpt_path='logs/Eff_monai_32z/lightning_logs/version_0/checkpoints/epoch=19-step=40.ckp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440add98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33bbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1454999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a48b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
